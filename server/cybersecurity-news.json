[
  {
    "creator": "Dell Cameron",
    "title": "CBP Signs Clearview AI Deal to Use Face Recognition for ‘Tactical Targeting’",
    "link": "https://www.wired.com/story/cbp-signs-clearview-ai-deal-to-use-face-recognition-for-tactical-targeting/",
    "pubDate": "Wed, 11 Feb 2026 16:32:27 +0000",
    "dc:creator": "Dell Cameron",
    "content": "US Border Patrol intelligence units will gain access to a face recognition tool built on billions of images scraped from the internet.",
    "contentSnippet": "US Border Patrol intelligence units will gain access to a face recognition tool built on billions of images scraped from the internet.",
    "guid": "698c844ca4a1ccc24a43ada1",
    "categories": [
      "Security",
      "Security / National Security",
      "Security / Privacy",
      "Security / Security News"
    ],
    "isoDate": "2026-02-11T16:32:27.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "APT36 and SideCopy Launch Cross-Platform RAT Campaigns Against Indian Entities",
    "link": "https://thehackernews.com/2026/02/apt36-and-sidecopy-launch-cross.html",
    "pubDate": "Wed, 11 Feb 2026 20:22:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbazpuuwU1rJbldu2fNhcDhnmgmpygU-Ci4lvjJXXo3TlmbV06oWZJ-FEJjMtQnkzg9-cBOt9h8aCA5d2EuO3gRaDlbzzc1w4cZRsdDUY1YwMTXv9f3ebp4CrZ-0jIar70HO_pyuhzHdClzTo85wpHJF8wiabXv8ko9fxQbp5WFmWdVwvtqqAkh5mk2_hv/s1600/india.jpg"
    },
    "content": "Indian defense sector and government-aligned organizations have been targeted by multiple campaigns that are designed to compromise Windows and Linux environments with remote access trojans capable of stealing sensitive data and ensuring continued access to infected machines.\nThe campaigns are characterized by the use of malware families like Geta RAT, Ares RAT, and DeskRAT, which are often",
    "contentSnippet": "Indian defense sector and government-aligned organizations have been targeted by multiple campaigns that are designed to compromise Windows and Linux environments with remote access trojans capable of stealing sensitive data and ensuring continued access to infected machines.\nThe campaigns are characterized by the use of malware families like Geta RAT, Ares RAT, and DeskRAT, which are often",
    "guid": "https://thehackernews.com/2026/02/apt36-and-sidecopy-launch-cross.html",
    "isoDate": "2026-02-11T14:52:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Bruce Schneier",
    "title": "Rewiring Democracy Ebook is on Sale",
    "link": "https://www.schneier.com/blog/archives/2026/02/rewiring-democracy-ebook-is-on-sale.html",
    "pubDate": "Wed, 11 Feb 2026 14:48:14 +0000",
    "content:encoded": "<p>I just noticed that the ebook version of <a href=\"https://www.schneier.com/books/rewiring-democracy/\"><i>Rewriring Democracy</i> is on sale for $5 on <a href=\"https://www.amazon.com/gp/product/B0DTNZ2H86\">Amazon</a>, <a\nhref=\"https://books.apple.com/us/book/rewiring-democracy/id6740839808\">Apple Books</a>, <a\nhref=\"https://www.barnesandnoble.com/w/rewiring-democracy-bruce-schneier/1146990469?ean=9780262384407\">Barnes &amp; Noble</a>, <a\nhref=\"https://www.booksamillion.com/p/Rewiring-Democracy/Bruce-Schneier/Q247907742\">Books A Million</a>, <a\nhref=\"https://play.google.com/store/books/details?id=QcNAEQAAQBAJ\">Google Play</a>, <a href=\"https://www.kobo.com/us/en/ebook/rewiring-democracy\">Kobo</a>, and presumably everywhere else in the US. I have no idea how long this will last.</p>\n",
    "content:encodedSnippet": "I just noticed that the ebook version of Rewriring Democracy is on sale for $5 on Amazon, Apple Books, Barnes & Noble, Books A Million, Google Play, Kobo, and presumably everywhere else in the US. I have no idea how long this will last.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2026/02/rewiring-democracy-ebook-is-on-sale.html#comments",
    "content": "<p>I just noticed that the ebook version of <a href=\"https://www.schneier.com/books/rewiring-democracy/\"><i>Rewriring Democracy</i> is on sale for $5 on <a href=\"https://www.amazon.com/gp/product/B0DTNZ2H86\">Amazon</a>, <a href=\"https://books.apple.com/us/book/rewiring-democracy/id6740839808\">Apple Books</a>, <a href=\"https://www.barnesandnoble.com/w/rewiring-democracy-bruce-schneier/1146990469?ean=9780262384407\">Barnes &#38; Noble</a>, <a href=\"https://www.booksamillion.com/p/Rewiring-Democracy/Bruce-Schneier/Q247907742\">Books A Million</a>, <a href=\"https://play.google.com/store/books/details?id=QcNAEQAAQBAJ\">Google Play</a>, <a href=\"https://www.kobo.com/us/en/ebook/rewiring-democracy\">Kobo</a>, and presumably everywhere else in the US. I have no idea how long this will last.</p>\n",
    "contentSnippet": "I just noticed that the ebook version of Rewriring Democracy is on sale for $5 on Amazon, Apple Books, Barnes & Noble, Books A Million, Google Play, Kobo, and presumably everywhere else in the US. I have no idea how long this will last.",
    "guid": "https://www.schneier.com/?p=71593",
    "categories": [
      "Uncategorized",
      "books",
      "ebooks",
      "Rewiring Democracy",
      "Schneier news"
    ],
    "isoDate": "2026-02-11T14:48:14.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Over 60 Software Vendors Issue Security Fixes Across OS, Cloud, and Network Platforms",
    "link": "https://thehackernews.com/2026/02/over-60-software-vendors-issue-security.html",
    "pubDate": "Wed, 11 Feb 2026 18:58:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjn9BjSz22uW2NPDNZhkDs7Ygjb5lTP5jFhXbGlk3oBRgpncWsp6pu42-c0T7TXDPviwihS5GuwedI6ULAmI6Zp8NKWOMzS-wJlSjVkd02cB6rM0uLbi-ZU1oxKsSQIpesNLkaA13EDcht62GZgjQbG2nffYeQPhXOWJHUBKhRwKm4s_-_ukeKZuno8I7Iv/s1600/patches.jpg"
    },
    "content": "It's Patch Tuesday, which means a number of software vendors have released patches for various security vulnerabilities impacting their products and services.\nMicrosoft issued fixes for 59 flaws, including six actively exploited zero-days in various Windows components that could be abused to bypass security features, escalate privileges, and trigger a denial-of-service (DoS) condition.\nElsewhere",
    "contentSnippet": "It's Patch Tuesday, which means a number of software vendors have released patches for various security vulnerabilities impacting their products and services.\nMicrosoft issued fixes for 59 flaws, including six actively exploited zero-days in various Windows components that could be abused to bypass security features, escalate privileges, and trigger a denial-of-service (DoS) condition.\nElsewhere",
    "guid": "https://thehackernews.com/2026/02/over-60-software-vendors-issue-security.html",
    "isoDate": "2026-02-11T13:28:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Bruce Schneier",
    "title": "Prompt Injection Via Road Signs",
    "link": "https://www.schneier.com/blog/archives/2026/02/prompt-injection-via-road-signs.html",
    "pubDate": "Wed, 11 Feb 2026 12:03:22 +0000",
    "content:encoded": "<p>Interesting research: &#8220;<a href=\"https://arxiv.org/pdf/2510.00181\">CHAI: Command Hijacking Against Embodied AI</a>.&#8221;</p>\n<blockquote><p><b>Abstract:</b> Embodied Artificial Intelligence (AI) promises to handle edge cases in robotic vehicle systems where data is scarce by using common-sense reasoning grounded in perception and action to generalize beyond training distributions and adapt to novel real-world situations. These capabilities, however, also create new security risks. In this paper, we introduce CHAI (Command Hijacking against embodied AI), a new class of prompt-based attacks that exploit the multimodal language interpretation abilities of Large Visual-Language Models (LVLMs). CHAI embeds deceptive natural language instructions, such as misleading signs, in visual input, systematically searches the token space, builds a dictionary of prompts, and guides an attacker model to generate Visual Attack Prompts. We evaluate CHAI on four LVLM agents; drone emergency landing, autonomous driving, and aerial object tracking, and on a real robotic vehicle. Our experiments show that CHAI consistently outperforms state-of-the-art attacks. By exploiting the semantic and multimodal reasoning strengths of next-generation embodied AI systems, CHAI underscores the urgent need for defenses that extend beyond traditional adversarial robustness.</p></blockquote>\n<p>News <a href=\"https://www.theregister.com/2026/01/30/road_sign_hijack_ai/\">article</a>.</p>\n",
    "content:encodedSnippet": "Interesting research: “CHAI: Command Hijacking Against Embodied AI.”\nAbstract: Embodied Artificial Intelligence (AI) promises to handle edge cases in robotic vehicle systems where data is scarce by using common-sense reasoning grounded in perception and action to generalize beyond training distributions and adapt to novel real-world situations. These capabilities, however, also create new security risks. In this paper, we introduce CHAI (Command Hijacking against embodied AI), a new class of prompt-based attacks that exploit the multimodal language interpretation abilities of Large Visual-Language Models (LVLMs). CHAI embeds deceptive natural language instructions, such as misleading signs, in visual input, systematically searches the token space, builds a dictionary of prompts, and guides an attacker model to generate Visual Attack Prompts. We evaluate CHAI on four LVLM agents; drone emergency landing, autonomous driving, and aerial object tracking, and on a real robotic vehicle. Our experiments show that CHAI consistently outperforms state-of-the-art attacks. By exploiting the semantic and multimodal reasoning strengths of next-generation embodied AI systems, CHAI underscores the urgent need for defenses that extend beyond traditional adversarial robustness.\n\nNews article.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2026/02/prompt-injection-via-road-signs.html#comments",
    "content": "<p>Interesting research: &#8220;<a href=\"https://arxiv.org/pdf/2510.00181\">CHAI: Command Hijacking Against Embodied AI</a>.&#8221;</p>\n<blockquote><p><b>Abstract:</b> Embodied Artificial Intelligence (AI) promises to handle edge cases in robotic vehicle systems where data is scarce by using common-sense reasoning grounded in perception and action to generalize beyond training distributions and adapt to novel real-world situations. These capabilities, however, also create new security risks. In this paper, we introduce CHAI (Command Hijacking against embodied AI), a new class of prompt-based attacks that exploit the multimodal language interpretation abilities of Large Visual-Language Models (LVLMs). CHAI embeds deceptive natural language instructions, such as misleading signs, in visual input, systematically searches the token space, builds a dictionary of prompts, and guides an attacker model to generate Visual Attack Prompts. We evaluate CHAI on four LVLM agents; drone emergency landing, autonomous driving, and aerial object tracking, and on a real robotic vehicle. Our experiments show that CHAI consistently outperforms state-of-the-art attacks. By exploiting the semantic and multimodal reasoning strengths of next-generation embodied AI systems, CHAI underscores the urgent need for defenses that extend beyond traditional adversarial robustness...</p></blockquote>",
    "contentSnippet": "Interesting research: “CHAI: Command Hijacking Against Embodied AI.”\nAbstract: Embodied Artificial Intelligence (AI) promises to handle edge cases in robotic vehicle systems where data is scarce by using common-sense reasoning grounded in perception and action to generalize beyond training distributions and adapt to novel real-world situations. These capabilities, however, also create new security risks. In this paper, we introduce CHAI (Command Hijacking against embodied AI), a new class of prompt-based attacks that exploit the multimodal language interpretation abilities of Large Visual-Language Models (LVLMs). CHAI embeds deceptive natural language instructions, such as misleading signs, in visual input, systematically searches the token space, builds a dictionary of prompts, and guides an attacker model to generate Visual Attack Prompts. We evaluate CHAI on four LVLM agents; drone emergency landing, autonomous driving, and aerial object tracking, and on a real robotic vehicle. Our experiments show that CHAI consistently outperforms state-of-the-art attacks. By exploiting the semantic and multimodal reasoning strengths of next-generation embodied AI systems, CHAI underscores the urgent need for defenses that extend beyond traditional adversarial robustness...",
    "guid": "https://www.schneier.com/?p=71577",
    "categories": [
      "Uncategorized",
      "academic papers",
      "AI",
      "cars",
      "hacking"
    ],
    "isoDate": "2026-02-11T12:03:22.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Exposed Training Open the Door for Crypto-Mining in Fortune 500 Cloud Environments",
    "link": "https://thehackernews.com/2026/02/exposed-training-open-door-for-crypto.html",
    "pubDate": "Wed, 11 Feb 2026 17:00:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiQeF3lExyDyGEAtnZylF2A30qkeG6Yoa-GxL_guF46TWzDUEyX7jg-j-PSO7VwdSUlFIalEmV2nCGE4KyntCePcUgW6qEBX6Mmj3rOpo5iTEqIjkQYd0YdeEOWjnpg5AWhfK0jO0wDksHchtMgjF8pq-lwcO-eHoyw2EqAGGqc48_UZRQsZ2R4ZxFG0bc/s1600/pentera.jpg"
    },
    "content": "Intentionally vulnerable training applications are widely used for security education, internal testing, and product demonstrations. Tools such as OWASP Juice Shop, DVWA, Hackazon, and bWAPP are designed to be insecure by default, making them useful for learning how common attack techniques work in controlled environments.\nThe issue is not the applications themselves, but how they are often",
    "contentSnippet": "Intentionally vulnerable training applications are widely used for security education, internal testing, and product demonstrations. Tools such as OWASP Juice Shop, DVWA, Hackazon, and bWAPP are designed to be insecure by default, making them useful for learning how common attack techniques work in controlled environments.\nThe issue is not the applications themselves, but how they are often",
    "guid": "https://thehackernews.com/2026/02/exposed-training-open-door-for-crypto.html",
    "isoDate": "2026-02-11T11:30:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Microsoft Patches 59 Vulnerabilities Including Six Actively Exploited Zero-Days",
    "link": "https://thehackernews.com/2026/02/microsoft-patches-59-vulnerabilities.html",
    "pubDate": "Wed, 11 Feb 2026 15:52:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhXD1L5ieHEU_h9-eg9LNbLb5-NpNemZK7bZbgYQS5MAeiHtGT2NyiQWOda0XOYhmj3wH_C0Bh4Nk8OzsXqAFaTCsja2EuPd_6t-V2R5PZjtwUQ2-74OWfUJKrJbRLy5n5qwchKcwcZ2Ns8DzYM_bE04nY9l3ntTbUXDi6OYxWO9EZmf8Ibv9YNBhUv6ejv/s1600/windows-updates.jpg"
    },
    "content": "Microsoft on Tuesday released security updates to address a set of 59 flaws across its software, including six vulnerabilities that it said have been exploited in the wild.\nOf the 59 flaws, five are rated Critical, 52 are rated Important, and two are rated Moderate in severity. Twenty-five of the patched vulnerabilities have been classified as privilege escalation, followed by remote code",
    "contentSnippet": "Microsoft on Tuesday released security updates to address a set of 59 flaws across its software, including six vulnerabilities that it said have been exploited in the wild.\nOf the 59 flaws, five are rated Critical, 52 are rated Important, and two are rated Moderate in severity. Twenty-five of the patched vulnerabilities have been classified as privilege escalation, followed by remote code",
    "guid": "https://thehackernews.com/2026/02/microsoft-patches-59-vulnerabilities.html",
    "isoDate": "2026-02-11T10:22:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "SSHStalker Botnet Uses IRC C2 to Control Linux Systems via Legacy Kernel Exploits",
    "link": "https://thehackernews.com/2026/02/sshstalker-botnet-uses-irc-c2-to.html",
    "pubDate": "Wed, 11 Feb 2026 15:26:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiIWksXdbZ0O2Uys7zlFHh363x_928N5gROvDQuqYlRb952YgIX5wXoIOhRZy6ZBS0Lswnax_SfsXm77mjIojyvIYLn8PQID-pGysGygXRuDj4MPbLlxHnwjVJ48IeW0Yf4K0Yw8mwxXkmFjYF3JnLoms3GbRYZbjWX28y2FuV2xyLFTaDM1NgQafp_j1uS/s1600/linux-botnet.jpg"
    },
    "content": "Cybersecurity researchers have disclosed details of a new botnet operation called SSHStalker that relies on the Internet Relay Chat (IRC) communication protocol for command-and-control (C2) purposes.\n\"The toolset blends stealth helpers with legacy-era Linux exploitation: Alongside log cleaners (utmp/wtmp/lastlog tampering) and rootkit-class artifacts, the actor keeps a large back-catalog of",
    "contentSnippet": "Cybersecurity researchers have disclosed details of a new botnet operation called SSHStalker that relies on the Internet Relay Chat (IRC) communication protocol for command-and-control (C2) purposes.\n\"The toolset blends stealth helpers with legacy-era Linux exploitation: Alongside log cleaners (utmp/wtmp/lastlog tampering) and rootkit-class artifacts, the actor keeps a large back-catalog of",
    "guid": "https://thehackernews.com/2026/02/sshstalker-botnet-uses-irc-c2-to.html",
    "isoDate": "2026-02-11T09:56:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "North Korea-Linked UNC1069 Uses AI Lures to Attack Cryptocurrency Organizations",
    "link": "https://thehackernews.com/2026/02/north-korea-linked-unc1069-uses-ai.html",
    "pubDate": "Wed, 11 Feb 2026 12:20:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1AmCdVPjXcdbUKaHP1fGGR1tT5hO6LUKR9OuPot9_CKjgucWXED-ta6q76tazonthjXXE6rpHZNiNbWi_V5XKJwfUX8Pqhciop7XuyOnQMnKMRTY1L3dp8ba1n4vkhi1W7MH1ZPKA1nnGxGCrBjjvBbjoHVCgRHgyamF5b_V_p276-aJ9_w6nR3f-qiNQ/s1600/crypto.jpg"
    },
    "content": "The North Korea-linked threat actor known as UNC1069 has been observed targeting the cryptocurrency sector to steal sensitive data from Windows and macOS systems with the ultimate goal of facilitating financial theft.\n\"The intrusion relied on a social engineering scheme involving a compromised Telegram account, a fake Zoom meeting, a ClickFix infection vector, and reported usage of AI-generated",
    "contentSnippet": "The North Korea-linked threat actor known as UNC1069 has been observed targeting the cryptocurrency sector to steal sensitive data from Windows and macOS systems with the ultimate goal of facilitating financial theft.\n\"The intrusion relied on a social engineering scheme involving a compromised Telegram account, a fake Zoom meeting, a ClickFix infection vector, and reported usage of AI-generated",
    "guid": "https://thehackernews.com/2026/02/north-korea-linked-unc1069-uses-ai.html",
    "isoDate": "2026-02-11T06:50:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "DPRK Operatives Impersonate Professionals on LinkedIn to Infiltrate Companies",
    "link": "https://thehackernews.com/2026/02/dprk-operatives-impersonate.html",
    "pubDate": "Tue, 10 Feb 2026 23:14:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjscdCXMOfFpYO0PkKXPhVwQXvjc7RNeTs0Wc79qPF6svrIVTW9mUaMX1qvJkDnuX7vpqcjjQoB6QRgA26lBjbjdTn12UPEOSHoWL0GTWWjsjdj1YsaGu3KpqZrfr-uFu21KDDlY3-mL8RfUzOaOjt_8wWFWB0yYAlscPY18sDhngfWTg_xsF2Wz7QEqfuj/s1600/northkorean.jpg"
    },
    "content": "The information technology (IT) workers associated with the Democratic People's Republic of Korea (DPRK) are now applying to remote positions using real LinkedIn accounts of individuals they're impersonating, marking a new escalation of the fraudulent scheme.\n\"These profiles often have verified workplace emails and identity badges, which DPRK operatives hope will make their fraudulent",
    "contentSnippet": "The information technology (IT) workers associated with the Democratic People's Republic of Korea (DPRK) are now applying to remote positions using real LinkedIn accounts of individuals they're impersonating, marking a new escalation of the fraudulent scheme.\n\"These profiles often have verified workplace emails and identity badges, which DPRK operatives hope will make their fraudulent",
    "guid": "https://thehackernews.com/2026/02/dprk-operatives-impersonate.html",
    "isoDate": "2026-02-10T17:44:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Reynolds Ransomware Embeds BYOVD Driver to Disable EDR Security Tools",
    "link": "https://thehackernews.com/2026/02/reynolds-ransomware-embeds-byovd-driver.html",
    "pubDate": "Tue, 10 Feb 2026 20:06:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjqTeSYoXhnTy-zKDDdC_mNC4M0z32QT7sAvTipDACRrlUcGRFE2rWJ3wGacGPtT8n9evbDa7H2cL0GRj8ABmUgdMvaS9UBi8fhZMkvoXV8BhfCGYeCMvmReDOgrTzB6hVf0dEZ6V_cA9wDhkwzDFdqhBtMOtibNJsge2YkohfspG3Z-y45_ysTjatb2M6F/s1600/edr.jpg"
    },
    "content": "Cybersecurity researchers have disclosed details of an emergent ransomware family dubbed Reynolds that comes embedded with a built-in bring your own vulnerable driver (BYOVD) component for defense evasion purposes within the ransomware payload itself.\nBYOVD refers to an adversarial technique that abuses legitimate but flawed driver software to escalate privileges and disable Endpoint Detection",
    "contentSnippet": "Cybersecurity researchers have disclosed details of an emergent ransomware family dubbed Reynolds that comes embedded with a built-in bring your own vulnerable driver (BYOVD) component for defense evasion purposes within the ransomware payload itself.\nBYOVD refers to an adversarial technique that abuses legitimate but flawed driver software to escalate privileges and disable Endpoint Detection",
    "guid": "https://thehackernews.com/2026/02/reynolds-ransomware-embeds-byovd-driver.html",
    "isoDate": "2026-02-10T14:36:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "From Ransomware to Residency: Inside the Rise of the Digital Parasite",
    "link": "https://thehackernews.com/2026/02/from-ransomware-to-residency-inside.html",
    "pubDate": "Tue, 10 Feb 2026 19:29:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgQoj8tRn4h4a-02GeyaLk1WyJz3XGX4AjYVezcSfqmsaz0v-9DZj6F1Tb6v7cAv7QaxHfnrZQtSZoOa1R5dwFLyNNhY369Lni0PKU-tfPndW0No6o9_wBUCLZpKVFdD762JQuhWRqmcLua6DqCBXbsvtVjtnIF7J_3JOL3h_7zl8nDP1qhv-C5H4Gqs1Y/s1600/picus.jpg"
    },
    "content": "Are ransomware and encryption still the defining signals of modern cyberattacks, or has the industry been too fixated on noise while missing a more dangerous shift happening quietly all around them?\nAccording to Picus Labs’ new Red Report 2026, which analyzed over 1.1 million malicious files and mapped 15.5 million adversarial actions observed across 2025, attackers are no longer optimizing for",
    "contentSnippet": "Are ransomware and encryption still the defining signals of modern cyberattacks, or has the industry been too fixated on noise while missing a more dangerous shift happening quietly all around them?\nAccording to Picus Labs’ new Red Report 2026, which analyzed over 1.1 million malicious files and mapped 15.5 million adversarial actions observed across 2025, attackers are no longer optimizing for",
    "guid": "https://thehackernews.com/2026/02/from-ransomware-to-residency-inside.html",
    "isoDate": "2026-02-10T13:59:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Fortinet Patches Critical SQLi Flaw Enabling Unauthenticated Code Execution",
    "link": "https://thehackernews.com/2026/02/fortinet-patches-critical-sqli-flaw.html",
    "pubDate": "Tue, 10 Feb 2026 19:00:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnvpWlJDRcbb7ljfQfr3-cgxfkViTJBw0bxfA9YRZxbXS7GWlhhOdByicULU6alislJQMfCcRjKjB3T_WJXNSH4EnAYMPHbg7G2WxCD3bug8W1aCPOsUCqG2p9_y4NGvKSpwGio3xsAbCsGALZtdn72ervcYQjY9eDhasnbDprcYmxUI-A-10PHaVtSdok/s1600/fort.jpg"
    },
    "content": "Fortinet has released security updates to address a critical flaw impacting FortiClientEMS that could lead to the execution of arbitrary code on susceptible systems.\nThe vulnerability, tracked as CVE-2026-21643, has a CVSS rating of 9.1 out of a maximum of 10.0.\n\n\"An improper neutralization of special elements used in an SQL Command ('SQL Injection') vulnerability [CWE-89] in FortiClientEMS may",
    "contentSnippet": "Fortinet has released security updates to address a critical flaw impacting FortiClientEMS that could lead to the execution of arbitrary code on susceptible systems.\nThe vulnerability, tracked as CVE-2026-21643, has a CVSS rating of 9.1 out of a maximum of 10.0.\n\n\"An improper neutralization of special elements used in an SQL Command ('SQL Injection') vulnerability [CWE-89] in FortiClientEMS may",
    "guid": "https://thehackernews.com/2026/02/fortinet-patches-critical-sqli-flaw.html",
    "isoDate": "2026-02-10T13:30:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Bruce Schneier",
    "title": "AI-Generated Text and the Detection Arms Race",
    "link": "https://www.schneier.com/blog/archives/2026/02/the-ai-generated-text-arms-race.html",
    "pubDate": "Tue, 10 Feb 2026 12:03:50 +0000",
    "content:encoded": "<p>In 2023, the science fiction literary magazine <cite>Clarkesworld</cite> <a href=\"https://www.npr.org/2023/02/24/1159286436/ai-chatbot-chatgpt-magazine-&lt;cite&gt;Clarkesworld&lt;/cite&gt;-artificial-intelligence\">stopped accepting</a> new submissions because so many were generated by artificial intelligence. Near as the editors could tell, many submitters pasted the magazine’s detailed story guidelines into an AI and sent in the results. And they weren’t alone. Other fiction magazines have also <a href=\"https://www.theverge.com/2023/2/25/23613752/ai-generated-short-stories-literary-magazines-&lt;cite&gt;Clarkesworld&lt;/cite&gt;-science-fiction\">reported a high number</a> of AI-generated submissions.</p>\n<p>This is only one example of a ubiquitous trend. A legacy system relied on the difficulty of writing and cognition to limit volume. Generative AI overwhelms the system because the humans on the receiving end can’t keep up.</p>\n<p>This is happening everywhere. Newspapers are being inundated by AI-generated <a href=\"https://www.nytimes.com/2025/11/04/science/letters-to-the-editor-ai-chatbots.html\">letters to the editor</a>, as are <a href=\"https://www.marketplace.org/episode/2025/11/24/ai-generated-letters-to-the-editor-are-flooding-academic-publications\">academic journals</a>. Lawmakers are inundated with AI-generated <a href=\"https://government.cornell.edu/news/lawmakers-struggle-differentiate-ai-and-human-emails\">constituent comments</a>. Courts around the world are flooded with AI-generated <a href=\"https://www.law.com/international-edition/2025/11/25/courts-being-flooded-by-wordy-ai-generated-documents-report-finds/\">filings</a>, particularly by people representing themselves. AI conferences are <a href=\"https://futurism.com/artificial-intelligence/ai-research-papers-slop\">flooded</a> with AI-generated research papers. Social media <a href=\"https://www.app.com/story/news/2025/12/07/how-to-deal-with-fake-ai-stories-popping-up-on-facebook-social-media/87629867007/\">is</a> <a href=\"https://www.nytimes.com/2025/12/08/technology/ai-slop-sora-social-media.html\">flooded</a> with <a href=\"https://www.cyberlink.com/blog/photo-marketing-business/3828/best-ai-social-media-post-generator\">AI posts</a>. In <a href=\"https://time.com/7338205/rage-against-ai-generated-music/\">music</a>, <a href=\"https://github.com/orgs/community/discussions/159749\">open source software</a>, <a href=\"https://www.newyorker.com/magazine/2025/07/07/the-end-of-the-english-paper\">education</a>, <a href=\"https://bsky.app/profile/eliothiggins.bsky.social/post/3m5yh2gjlj22b\">investigative journalism</a> and <a href=\"https://www.nytimes.com/2025/06/21/business/dealbook/ai-job-applications.html\">hiring</a>, it’s the same story.</p>\n<p>Like <cite>Clarkesworld</cite>’s initial response, some of these institutions shut down their submissions processes. Others have met the offensive of AI inputs with some defensive response, often involving a counteracting use of AI. Academic <a href=\"https://doi.org/10.1038/d41586-025-03506-6\">peer reviewers</a> increasingly use AI to evaluate papers that may have been generated by AI. Social media platforms turn to <a href=\"https://www.integrityinstitute.org/blog/how-generative-ai-makes-content-moderation-both-harder-and-easier\">AI moderators</a>. Court systems use AI to <a href=\"https://restofworld.org/2025/brazil-ai-courts-lawsuits/\">triage and process</a> litigation volumes supercharged by AI. Employers turn to <a href=\"https://www.forbes.com/sites/mariagraciasantillanalinares/2025/12/16/job-applicant-fraud-is-rising-this-startup-is-using-ai-to-stop-it/\">AI tools</a> to review candidate applications. Educators use AI not just to <a href=\"https://www.cnn.com/2024/04/06/tech/teachers-grading-ai\">grade papers</a> and <a href=\"https://www.behind-the-enemy-lines.com/2025/12/fighting-fire-with-fire-scalable-oral.html\">administer exams</a>, but as a <a href=\"https://wacclearinghouse.org/repository/collections/textgened/rhetorical-engagements/using-llms-as-peer-reviewers-for-revising-essays/\">feedback</a> tool for students.</p>\n<p>These are all arms races: rapid, adversarial iteration to apply a common technology to opposing purposes. Many of these arms races have clearly deleterious effects. Society suffers if the courts are clogged with frivolous, AI-manufactured cases. There is also harm if the established measures of academic performance – publications and citations – accrue to those researchers most willing to fraudulently submit AI-written letters and papers rather than to those whose ideas have the most impact. The fear is that, in the end, fraudulent behavior enabled by AI will undermine systems and institutions that society relies on.</p>\n<h3>Upsides of AI</h3>\n<p>Yet some of these AI arms races have surprising hidden upsides, and the hope is that at least some institutions will be able to change in ways that make them stronger.</p>\n<p>Science seems likely to become stronger thanks to AI, yet it faces a problem when the AI makes mistakes. Consider the example of <a href=\"https://theconversation.com/a-weird-phrase-is-plaguing-scientific-papers-and-we-traced-it-back-to-a-glitch-in-ai-training-data-254463\">nonsensical</a>, AI-generated phrasing filtering into scientific papers.</p>\n<p>A scientist using an AI to assist in writing an academic paper can be a good thing, if used carefully and with disclosure. AI is increasingly a <a href=\"https://www.nature.com/articles/s43588-025-00890-x\">primary tool</a> in scientific research: for reviewing literature, programming and for coding and analyzing data. And for many, it has become a crucial support for expression and scientific communication. Pre-AI, better-funded researchers could hire humans to help them write their academic papers. For many authors whose primary language is not English, hiring this kind of assistance has been an expensive <a href=\"https://doi.org/10.1098/rspb.2023.2840\">necessity</a>. AI provides it to everyone.</p>\n<p>In fiction, fraudulently submitted AI-generated works cause harm, both to the human authors now subject to increased competition and to those readers who may feel defrauded after unknowingly reading the work of a machine. But some outlets may welcome AI-assisted submissions with appropriate disclosure and under particular guidelines, and leverage AI to evaluate them against criteria like originality, fit and quality.</p>\n<p>Others may refuse AI-generated work, but this will come at a cost. It’s unlikely that any human editor or technology can sustain an ability to differentiate human from machine writing. Instead, outlets that wish to exclusively publish humans will need to limit submissions to a set of authors they trust to not use AI. If these policies are transparent, readers can pick the format they prefer and read happily from either or both types of outlets.</p>\n<p>We also don’t see any problem if a job seeker uses AI to polish their resumes or write better cover letters: The wealthy and privileged have long had access to human assistance for those things. But it crosses the line when AIs are used to <a href=\"https://www.cbsnews.com/news/fake-job-seekers-flooding-market-artificial-intelligence/\">lie</a> about identity and experience, or to <a href=\"https://www.theatlantic.com/technology/2025/10/ai-cheating-job-interviews-fraud/684568/\">cheat</a> on job interviews.</p>\n<p>Similarly, a democracy requires that its citizens be able to express their opinions to their representatives, or to each other through a medium like the newspaper. The rich and powerful have long been able to hire writers to turn their ideas into persuasive prose, and AIs providing that assistance to more people is a good thing, in our view. Here, AI mistakes and bias can be harmful. Citizens may be using AI for more than just a time-saving shortcut; it may be augmenting their knowledge and capabilities, generating statements about historical, legal or policy factors they can’t reasonably be expected to independently check.</p>\n<h3>Fraud booster</h3>\n<p>What we don’t want is for lobbyists to use AIs in astroturf campaigns, writing multiple letters and passing them off as individual opinions. This, too, is an <a href=\"https://www.washingtonpost.com/politics/2021/05/14/millions-fake-commenters-asked-fcc-end-net-neutrality-astroturfing-is-business-model/\">older problem</a> that AIs are making worse.</p>\n<p>What differentiates the positive from the negative here is not any inherent aspect of the technology, it’s the power dynamic. The same technology that reduces the effort required for a citizen to share their lived experience with their legislator also enables corporate interests to misrepresent the public at scale. The former is a power-equalizing application of AI that enhances participatory democracy; the latter is a power-concentrating application that threatens it.</p>\n<p>In general, we believe writing and cognitive assistance, long available to the rich and powerful, should be available to everyone. The problem comes when AIs make fraud easier. Any response needs to balance embracing that newfound democratization of access with preventing fraud.</p>\n<p>There’s no way to turn this technology off. Highly capable AIs are widely available and can run on a laptop. Ethical guidelines and clear professional boundaries can help – for those acting in good faith. But there won’t ever be a way to totally stop academic writers, job seekers or citizens from using these tools, either as legitimate assistance or to commit fraud. This means more comments, more letters, more applications, more submissions.</p>\n<p>The problem is that whoever is on the receiving end of this AI-fueled deluge can’t deal with the increased volume. What can help is developing assistive AI tools that benefit institutions and society, while also limiting fraud. And that may mean embracing the use of AI assistance in these adversarial systems, even though the defensive AI will never achieve supremacy.</p>\n<h3>Balancing harms with benefits</h3>\n<p>The science fiction community has been wrestling with AI since 2023. <cite>Clarkesworld</cite> eventually reopened submissions, <a href=\"https://www.postalley.org/2024/06/04/the-big-sort-how-will-ai-affect-submissions-to-magazines/\">claiming</a> that it has an adequate way of separating human- and AI-written stories. No one knows how long, or how well, that will continue to work.</p>\n<p>The arms race continues. There is no simple way to tell whether the potential benefits of AI will outweigh the harms, now or in the future. But as a society, we can influence the balance of harms it wreaks and opportunities it presents as we muddle our way through the changing technological landscape.</p>\n<p><a href=\"https://theconversation.com/ai-generated-text-is-overwhelming-institutions-setting-off-a-no-win-arms-race-with-ai-detectors-274720\"><em>This essay was written with Nathan E. Sanders, and originally appeared in The Conversation.</em></a></p>\n<p>EDITED TO ADD: This essay has been translated into <a href=\"https://www.elconfidencial.com/tecnologia/novaceno/2026-02-07/ia-derriba-sociedad-educacion-legal-medios_4298791/\">Spanish</a>.</p>\n",
    "content:encodedSnippet": "In 2023, the science fiction literary magazine Clarkesworld stopped accepting new submissions because so many were generated by artificial intelligence. Near as the editors could tell, many submitters pasted the magazine’s detailed story guidelines into an AI and sent in the results. And they weren’t alone. Other fiction magazines have also reported a high number of AI-generated submissions.\nThis is only one example of a ubiquitous trend. A legacy system relied on the difficulty of writing and cognition to limit volume. Generative AI overwhelms the system because the humans on the receiving end can’t keep up.\nThis is happening everywhere. Newspapers are being inundated by AI-generated letters to the editor, as are academic journals. Lawmakers are inundated with AI-generated constituent comments. Courts around the world are flooded with AI-generated filings, particularly by people representing themselves. AI conferences are flooded with AI-generated research papers. Social media is flooded with AI posts. In music, open source software, education, investigative journalism and hiring, it’s the same story.\nLike Clarkesworld’s initial response, some of these institutions shut down their submissions processes. Others have met the offensive of AI inputs with some defensive response, often involving a counteracting use of AI. Academic peer reviewers increasingly use AI to evaluate papers that may have been generated by AI. Social media platforms turn to AI moderators. Court systems use AI to triage and process litigation volumes supercharged by AI. Employers turn to AI tools to review candidate applications. Educators use AI not just to grade papers and administer exams, but as a feedback tool for students.\nThese are all arms races: rapid, adversarial iteration to apply a common technology to opposing purposes. Many of these arms races have clearly deleterious effects. Society suffers if the courts are clogged with frivolous, AI-manufactured cases. There is also harm if the established measures of academic performance – publications and citations – accrue to those researchers most willing to fraudulently submit AI-written letters and papers rather than to those whose ideas have the most impact. The fear is that, in the end, fraudulent behavior enabled by AI will undermine systems and institutions that society relies on.\nUpsides of AI\nYet some of these AI arms races have surprising hidden upsides, and the hope is that at least some institutions will be able to change in ways that make them stronger.\nScience seems likely to become stronger thanks to AI, yet it faces a problem when the AI makes mistakes. Consider the example of nonsensical, AI-generated phrasing filtering into scientific papers.\nA scientist using an AI to assist in writing an academic paper can be a good thing, if used carefully and with disclosure. AI is increasingly a primary tool in scientific research: for reviewing literature, programming and for coding and analyzing data. And for many, it has become a crucial support for expression and scientific communication. Pre-AI, better-funded researchers could hire humans to help them write their academic papers. For many authors whose primary language is not English, hiring this kind of assistance has been an expensive necessity. AI provides it to everyone.\nIn fiction, fraudulently submitted AI-generated works cause harm, both to the human authors now subject to increased competition and to those readers who may feel defrauded after unknowingly reading the work of a machine. But some outlets may welcome AI-assisted submissions with appropriate disclosure and under particular guidelines, and leverage AI to evaluate them against criteria like originality, fit and quality.\nOthers may refuse AI-generated work, but this will come at a cost. It’s unlikely that any human editor or technology can sustain an ability to differentiate human from machine writing. Instead, outlets that wish to exclusively publish humans will need to limit submissions to a set of authors they trust to not use AI. If these policies are transparent, readers can pick the format they prefer and read happily from either or both types of outlets.\nWe also don’t see any problem if a job seeker uses AI to polish their resumes or write better cover letters: The wealthy and privileged have long had access to human assistance for those things. But it crosses the line when AIs are used to lie about identity and experience, or to cheat on job interviews.\nSimilarly, a democracy requires that its citizens be able to express their opinions to their representatives, or to each other through a medium like the newspaper. The rich and powerful have long been able to hire writers to turn their ideas into persuasive prose, and AIs providing that assistance to more people is a good thing, in our view. Here, AI mistakes and bias can be harmful. Citizens may be using AI for more than just a time-saving shortcut; it may be augmenting their knowledge and capabilities, generating statements about historical, legal or policy factors they can’t reasonably be expected to independently check.\nFraud booster\nWhat we don’t want is for lobbyists to use AIs in astroturf campaigns, writing multiple letters and passing them off as individual opinions. This, too, is an older problem that AIs are making worse.\nWhat differentiates the positive from the negative here is not any inherent aspect of the technology, it’s the power dynamic. The same technology that reduces the effort required for a citizen to share their lived experience with their legislator also enables corporate interests to misrepresent the public at scale. The former is a power-equalizing application of AI that enhances participatory democracy; the latter is a power-concentrating application that threatens it.\nIn general, we believe writing and cognitive assistance, long available to the rich and powerful, should be available to everyone. The problem comes when AIs make fraud easier. Any response needs to balance embracing that newfound democratization of access with preventing fraud.\nThere’s no way to turn this technology off. Highly capable AIs are widely available and can run on a laptop. Ethical guidelines and clear professional boundaries can help – for those acting in good faith. But there won’t ever be a way to totally stop academic writers, job seekers or citizens from using these tools, either as legitimate assistance or to commit fraud. This means more comments, more letters, more applications, more submissions.\nThe problem is that whoever is on the receiving end of this AI-fueled deluge can’t deal with the increased volume. What can help is developing assistive AI tools that benefit institutions and society, while also limiting fraud. And that may mean embracing the use of AI assistance in these adversarial systems, even though the defensive AI will never achieve supremacy.\nBalancing harms with benefits\nThe science fiction community has been wrestling with AI since 2023. Clarkesworld eventually reopened submissions, claiming that it has an adequate way of separating human- and AI-written stories. No one knows how long, or how well, that will continue to work.\nThe arms race continues. There is no simple way to tell whether the potential benefits of AI will outweigh the harms, now or in the future. But as a society, we can influence the balance of harms it wreaks and opportunities it presents as we muddle our way through the changing technological landscape.\nThis essay was written with Nathan E. Sanders, and originally appeared in The Conversation.\nEDITED TO ADD: This essay has been translated into Spanish.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2026/02/the-ai-generated-text-arms-race.html#comments",
    "content": "<p>In 2023, the science fiction literary magazine <cite>Clarkesworld</cite> <a href=\"https://www.npr.org/2023/02/24/1159286436/ai-chatbot-chatgpt-magazine-&#60;cite&#62;Clarkesworld&#60;/cite&#62;-artificial-intelligence\">stopped accepting</a> new submissions because so many were generated by artificial intelligence. Near as the editors could tell, many submitters pasted the magazine’s detailed story guidelines into an AI and sent in the results. And they weren’t alone. Other fiction magazines have also <a href=\"https://www.theverge.com/2023/2/25/23613752/ai-generated-short-stories-literary-magazines-&#60;cite&#62;Clarkesworld&#60;/cite&#62;-science-fiction\">reported a high number</a> of AI-generated submissions.</p>\n<p>This is only one example of a ubiquitous trend. A legacy system relied on the difficulty of writing and cognition to limit volume. Generative AI overwhelms the system because the humans on the receiving end can’t keep up...</p>",
    "contentSnippet": "In 2023, the science fiction literary magazine Clarkesworld stopped accepting new submissions because so many were generated by artificial intelligence. Near as the editors could tell, many submitters pasted the magazine’s detailed story guidelines into an AI and sent in the results. And they weren’t alone. Other fiction magazines have also reported a high number of AI-generated submissions.\nThis is only one example of a ubiquitous trend. A legacy system relied on the difficulty of writing and cognition to limit volume. Generative AI overwhelms the system because the humans on the receiving end can’t keep up...",
    "guid": "https://www.schneier.com/?p=71563",
    "categories": [
      "Uncategorized",
      "AI",
      "LLM"
    ],
    "isoDate": "2026-02-10T12:03:50.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "ZAST.AI Raises $6M Pre-A to Scale \"Zero False Positive\" AI-Powered Code Security",
    "link": "https://thehackernews.com/2026/02/zastai-raises-6m-pre-to-scale-zero.html",
    "pubDate": "Tue, 10 Feb 2026 17:10:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiHKbU6u4lVkqpxF5kGQqL_tox5POYTtIOFqB3eSIifgkcdHqwrcHFmpalRBqZnEMMDAvTrtmoNBIq368ZKLCLOHZLQu7zZAsJMUje1bGwcvbdywaNs25e84labbIA72VFmtB3YmyBi-9yJPMqdDu48Kf_5BfLraAS1JlzR9AXSD3TrKmwIITpje0AkgI/s1600/zast.gif"
    },
    "content": "January 5, 2026, Seattle, USA — ZAST.AI announced the completion of a $6 million Pre-A funding round. This investment came from the well-known investment firm Hillhouse Capital, bringing ZAST.AI's total funding close to $10 million. This marks a recognition from leading capital markets of a new solution: ending the era of high false positive rates in security tools and making every alert",
    "contentSnippet": "January 5, 2026, Seattle, USA — ZAST.AI announced the completion of a $6 million Pre-A funding round. This investment came from the well-known investment firm Hillhouse Capital, bringing ZAST.AI's total funding close to $10 million. This marks a recognition from leading capital markets of a new solution: ending the era of high false positive rates in security tools and making every alert",
    "guid": "https://thehackernews.com/2026/02/zastai-raises-6m-pre-to-scale-zero.html",
    "isoDate": "2026-02-10T11:40:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Warlock Ransomware Breaches SmarterTools Through Unpatched SmarterMail Server",
    "link": "https://thehackernews.com/2026/02/warlock-ransomware-breaches.html",
    "pubDate": "Tue, 10 Feb 2026 15:54:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQg_RBFvjX4CSOktzf6QU0KcmxaSjFhOLkaPXZkzfoqHaq2A4TUCu-GxQCBQsKTK3PoDM-RLpolaRFIdbityIpVRtZA-5-VK2aYjRQZl0NWsHCpw-VrIkgUOYvOi4Pg0Le44LPnmMb5xQYQ4r3V6WT8Ukll2rt6mTBCRCFE3f3OD1LJCBK6G0XBAExHTw0/s1600/smart.jpg"
    },
    "content": "SmarterTools confirmed last week that the Warlock (aka Storm-2603) ransomware gang breached its network by exploiting an unpatched SmarterMail instance.\nThe incident took place on January 29, 2026, when a mail server that was not updated to the latest version was compromised, the company's Chief Commercial Officer, Derek Curtis, said.\n\"Prior to the breach, we had approximately 30 servers/VMs",
    "contentSnippet": "SmarterTools confirmed last week that the Warlock (aka Storm-2603) ransomware gang breached its network by exploiting an unpatched SmarterMail instance.\nThe incident took place on January 29, 2026, when a mail server that was not updated to the latest version was compromised, the company's Chief Commercial Officer, Derek Curtis, said.\n\"Prior to the breach, we had approximately 30 servers/VMs",
    "guid": "https://thehackernews.com/2026/02/warlock-ransomware-breaches.html",
    "isoDate": "2026-02-10T10:24:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Dutch Authorities Confirm Ivanti Zero-Day Exploit Exposed Employee Contact Data",
    "link": "https://thehackernews.com/2026/02/dutch-authorities-confirm-ivanti-zero.html",
    "pubDate": "Tue, 10 Feb 2026 13:52:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhkGwO0dfI4hVFSzIpnPbDAGzLfh0FJh-3jiKa-mSrkIRuXECaLjAb1Yh9nM8I4KrZ40fAX4eYwHyQyVNRGJDCXkq6uzf5Tm0L0uiMb8buN2iEs-x4bw6ywRLTvaO5eLyiXr614f_0ekstIPre9e_Yw576ptePRbRqcjmxcmu4hxlJ5O9UHPa79j9PGi3vg/s1600/Ivanti.jpg"
    },
    "content": "The Netherlands' Dutch Data Protection Authority (AP) and the Council for the Judiciary confirmed both agencies (Rvdr) have disclosed that their systems were impacted by cyber attacks that exploited the recently disclosed security flaws in Ivanti Endpoint Manager Mobile (EPMM), according to a notice sent to the country's parliament on Friday.\n\"On January 29, the National Cyber Security Center (",
    "contentSnippet": "The Netherlands' Dutch Data Protection Authority (AP) and the Council for the Judiciary confirmed both agencies (Rvdr) have disclosed that their systems were impacted by cyber attacks that exploited the recently disclosed security flaws in Ivanti Endpoint Manager Mobile (EPMM), according to a notice sent to the country's parliament on Friday.\n\"On January 29, the National Cyber Security Center (",
    "guid": "https://thehackernews.com/2026/02/dutch-authorities-confirm-ivanti-zero.html",
    "isoDate": "2026-02-10T08:22:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "China-Linked UNC3886 Targets Singapore Telecom Sector in Cyber Espionage Campaign",
    "link": "https://thehackernews.com/2026/02/china-linked-unc3886-targets-singapore.html",
    "pubDate": "Mon, 09 Feb 2026 22:31:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEitWC7fuHQt0LEMJmwl8Nv8meCzOQQJ4XuPacIEsqxLrSxPLslJjapg-02Nmzb8ngITdSXT-C_cLn1JYF4KDUAH3bpuFyb9qznZkD8A3m-wotkulB0yflFBcAFgPuU0Ci8DYloAZGFJecZyrByApcTSCSB8Kqg6wki4UYqTt9pQPXmnkqVOMxZyfWx9820Z/s1600/chinese-telecom.jpg"
    },
    "content": "The Cyber Security Agency (CSA) of Singapore on Monday revealed that the China-nexus cyber espionage group known as UNC3886 targeted its telecommunications sector.\n\"UNC3886 had launched a deliberate, targeted, and well-planned campaign against Singapore's telecommunications sector,\" CSA said. \"All four of Singapore's major telecommunications operators ('telcos') – M1, SIMBA Telecom, Singtel, and",
    "contentSnippet": "The Cyber Security Agency (CSA) of Singapore on Monday revealed that the China-nexus cyber espionage group known as UNC3886 targeted its telecommunications sector.\n\"UNC3886 had launched a deliberate, targeted, and well-planned campaign against Singapore's telecommunications sector,\" CSA said. \"All four of Singapore's major telecommunications operators ('telcos') – M1, SIMBA Telecom, Singtel, and",
    "guid": "https://thehackernews.com/2026/02/china-linked-unc3886-targets-singapore.html",
    "isoDate": "2026-02-09T17:01:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "SolarWinds Web Help Desk Exploited for RCE in Multi-Stage Attacks on Exposed Servers",
    "link": "https://thehackernews.com/2026/02/solarwinds-web-help-desk-exploited-for.html",
    "pubDate": "Mon, 09 Feb 2026 20:12:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1coFDcJGaV6fnBzpBs3TXSas4-odFMjYTlXPM-cyQcpzDyCshc0pH8HMEo1XmNUoVPRU4J56lg3ApR_-KpFn8L6aiATW4A5Xx_cIUbCYO1MI9W6lTiW-vlJWPK7Bc-SkXNcjQ-CnP7_HCOwhRYn1HsJnuE6sCOQZ6S4m-LC3zySGT_mHorlhwwJA4SLlO/s1600/1000054453.jpg"
    },
    "content": "Microsoft has revealed that it observed a multi‑stage intrusion that involved the threat actors exploiting internet‑exposed SolarWinds Web Help Desk (WHD) instances to obtain initial access and move laterally across the organization's network to other high-value assets.\nThat said, the Microsoft Defender Security Research Team said it's not clear whether the activity weaponized recently",
    "contentSnippet": "Microsoft has revealed that it observed a multi‑stage intrusion that involved the threat actors exploiting internet‑exposed SolarWinds Web Help Desk (WHD) instances to obtain initial access and move laterally across the organization's network to other high-value assets.\nThat said, the Microsoft Defender Security Research Team said it's not clear whether the activity weaponized recently",
    "guid": "https://thehackernews.com/2026/02/solarwinds-web-help-desk-exploited-for.html",
    "isoDate": "2026-02-09T14:42:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "⚡ Weekly Recap: AI Skill Malware, 31Tbps DDoS, Notepad++ Hack, LLM Backdoors and More",
    "link": "https://thehackernews.com/2026/02/weekly-recap-ai-skill-malware-31tbps.html",
    "pubDate": "Mon, 09 Feb 2026 18:29:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiUQI___vJxIaWlqG1lWOUAxD5Ur1U6VZA2denhtk0dqfyI4yIlzqTGJkg1vqQVn5twAhjY9JraokCa2Ly2xBoZ4wXwX5XRncJcZpbANC1j8RtIBi9-jezYgF56QIny6kJRuqCXqgVGXQWX935VYiaLlPqu88xmqmg5n2_PJgtFZsx75cnOAlgWcyp0A_SK/s1600/recap-main.jpg"
    },
    "content": "Cyber threats are no longer coming from just malware or exploits. They’re showing up inside the tools, platforms, and ecosystems organizations use every day. As companies connect AI, cloud apps, developer tools, and communication systems, attackers are following those same paths.\nA clear pattern this week: attackers are abusing trust. Trusted updates, trusted marketplaces, trusted apps, even",
    "contentSnippet": "Cyber threats are no longer coming from just malware or exploits. They’re showing up inside the tools, platforms, and ecosystems organizations use every day. As companies connect AI, cloud apps, developer tools, and communication systems, attackers are following those same paths.\nA clear pattern this week: attackers are abusing trust. Trusted updates, trusted marketplaces, trusted apps, even",
    "guid": "https://thehackernews.com/2026/02/weekly-recap-ai-skill-malware-31tbps.html",
    "isoDate": "2026-02-09T12:59:00.000Z",
    "itunes": {}
  }
]