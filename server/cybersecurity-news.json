[
  {
    "creator": "Bruce Schneier",
    "title": "Like Social Media, AI Requires Difficult Choices",
    "link": "https://www.schneier.com/blog/archives/2025/12/like-social-media-ai-requires-difficult-choices.html",
    "pubDate": "Tue, 02 Dec 2025 12:03:01 +0000",
    "content:encoded": "<p>In his 2020 book, &#8220;<a href=\"https://global.oup.com/academic/product/future-politics-9780198825616?cc=ca&amp;lang=en&amp;\">Future Politics</a><em>,</em>&#8221; British barrister Jamie Susskind wrote that the dominant question of the 20th century was &#8220;How much of our collective life should be determined by the state, and what should be left to the market and civil society?&#8221; But in the early decades of this century, Susskind suggested that we face a different question: &#8220;To what extent should our lives be directed and controlled by powerful digital systems&#8212;and on what terms?&#8221;</p>\n<p>Artificial intelligence (AI) forces us to confront this question. It is a technology that in theory amplifies the power of its users: A manager, marketer, political campaigner, or opinionated internet user can utter a single instruction, and see their message&#8212;whatever it is&#8212;instantly written, personalized, and propagated via email, text, social, or other channels to thousands of people within their organization, or millions around the world. It also allows us to individualize solicitations for political donations, elaborate a grievance into a well-articulated policy position, or tailor a persuasive argument to an identity group, or even a single person.</p>\n<p>But even as it offers endless potential, AI is a technology that&#8212;like the state&#8212;gives others new powers to control our lives and experiences.</p>\n<p>We&#8217;ve seen this out play before. Social media companies made <a href=\"https://www.technologyreview.com/2024/03/13/1089729/lets-not-make-the-same-mistakes-with-ai-that-we-made-with-social-media/\">the same sorts of promises</a> 20 years ago: instant communication enabling individual connection at massive scale. Fast-forward to today, and the technology that was supposed to give individuals power and influence ended up controlling us. Today social media dominates our <a href=\"https://www.ntu.edu.sg/news/detail/international-study-shows-impact-of-social-media-on-young-people\">time and attention</a>, <a href=\"https://www.hhs.gov/sites/default/files/sg-youth-mental-health-social-media-advisory.pdf\">assaults our mental health</a>, and&#8212;together with its Big Tech parent companies&#8212;captures an <a href=\"https://www.bankrate.com/investing/trillion-dollar-companies/\">unfathomable fraction of our economy</a>, even as it <a href=\"https://www.fastcompany.com/91428050/ai-democracy-insights-to-remember\">poses risks to our democracy</a>.</p>\n<p>The novelty and potential of social media was as present then as it is for AI now, which should make us wary of its potential harmful consequences for society and democracy. We legitimately fear artificial voices and manufactured reality drowning out real people on the internet: on social media, in chat rooms, everywhere we might try to connect with others.</p>\n<p>It doesn&#8217;t have to be that way. Alongside these evident risks, AI has <a href=\"https://mitpress.mit.edu/9780262049948/rewiring-democracy/\">legitimate potential</a> to transform both everyday life and democratic governance in <a href=\"https://www.theguardian.com/commentisfree/2025/nov/23/ai-use-strengthen-democracy\">positive ways</a>. In our new book, &#8220;<a href=\"https://mitpress.mit.edu/9780262049948/rewiring-democracy/\">Rewiring Democracy</a>,&#8221; we chronicle examples from around the globe of democracies using AI to make regulatory enforcement more efficient, catch tax cheats, speed up judicial processes, synthesize input from constituents to legislatures, and much more. Because democracies distribute power across institutions and individuals, making the right choices about how to shape AI and its uses requires both clarity and alignment across society.</p>\n<p>To that end, we spotlight four pivotal choices facing private and public actors. These choices are similar to those we faced during the advent of social media, and in retrospect we can see that we made the wrong decisions back then. Our collective choices in 2025&#8212;choices made by tech CEOs, politicians, and citizens alike&#8212;may dictate whether AI is applied to positive and pro-democratic, or harmful and civically destructive, ends.</p>\n<h3>A Choice for the Executive and the Judiciary: Playing by the Rules</h3>\n<p>The Federal Election Commission (FEC) calls it fraud when a candidate hires an actor to impersonate their opponent. More recently, <a href=\"https://ash.harvard.edu/articles/whos-accountable-for-ai-usage-in-digital-campaign-ads-right-now-no-one/\">they had to decide</a> whether doing the same thing with an AI deepfake makes it okay. (<a href=\"https://www.fec.gov/updates/commission-approves-notification-of-disposition-interpretive-rule-on-artificial-intelligence-in-campaign-ads/\">They concluded it does not</a>.) Although in this case the FEC made the right decision, this is just one example of how AIs could skirt laws that govern people.</p>\n<p>Likewise, courts are having to decide if and when it is okay for an AI to reuse creative materials without compensation or attribution, which might constitute plagiarism or copyright infringement if carried out by a human. (The <a href=\"https://www.eff.org/deeplinks/2025/02/copyright-and-ai-cases-and-consequences\">court outcomes so far are mixed</a>.) Courts are also adjudicating whether corporations are responsible for upholding promises made by AI customer service representatives. (In the case of <a href=\"https://www.bbc.com/travel/article/20240222-air-canada-chatbot-misinformation-what-travellers-should-know\">Air Canada</a>, the answer was yes, and insurers have <a href=\"https://www.ft.com/content/1d35759f-f2a9-46c4-904b-4a78ccc027df\">started covering the liability</a>.)</p>\n<p>Social media companies faced many of the same hazards decades ago and <a href=\"https://www.crowell.com/en/insights/client-alerts/the-cda-and-dmca-recent-developments-and-how-they-work-together-to-regulate-online-services\">have largely been shielded</a> by the combination of Section 230 of the Communications Act of 1994 and the safe harbor offered by the Digital Millennium Copyright Act of 1998. Even in the absence of congressional action to strengthen or add rigor to this law, the Federal Communications Commission (FCC) and the Supreme Court could take action to enhance its effects and to clarify which humans are responsible when technology is used, in effect, to bypass existing law.</p>\n<h3>A Choice for Congress: Privacy</h3>\n<p>As AI-enabled products increasingly ask Americans to share yet more of their personal information&#8212;<a href=\"https://www.economist.com/by-invitation/2025/09/09/ai-agents-are-coming-for-your-privacy-warns-meredith-whittaker\">their &#8220;context</a>&#8220;&#8212;to use digital services like personal assistants, safeguarding the interests of the American consumer should be a bipartisan cause in Congress.</p>\n<p>It has been nearly 10 years since Europe adopted comprehensive <a href=\"https://gdpr-info.eu/\">data privacy regulation</a>. Today, American companies exert massive efforts to limit data collection, acquire consent for use of data, and hold it confidential under significant financial penalties&#8212;but only for their customers and users in the EU.</p>\n<p>Regardless, a decade later the U.S. has <a href=\"https://www.techpolicy.press/is-there-any-way-forward-for-privacy-legislation-in-the-united-states/\">still failed to make progress</a> on any serious attempts at comprehensive federal privacy legislation written for the 21st century, and there are <a href=\"https://www.dlapiperdataprotection.com/?c=US\">precious few data privacy protections</a> that apply to narrow slices of the economy and population. This inaction comes in spite of scandal after scandal regarding Big Tech corporations&#8217; irresponsible and harmful use of our personal data: <a href=\"https://techhq.com/news/oracle-facing-data-backlash-for-violating-the-privacy-of-billions/\">Oracle&#8217;s data profiling</a>, Facebook and <a href=\"https://www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.html\">Cambridge Analytica</a>, <a href=\"https://www.bbc.com/news/articles/c3dr91z0g4zo\">Google ignoring data privacy opt-out requests</a>, and many more.</p>\n<p>Privacy is just one side of the obligations AI companies should have with respect to our data; the other side is portability&#8212;that is, the ability for individuals to choose to migrate and share their data between consumer tools and technology systems. To the extent that knowing our personal context really does enable better and more personalized AI services, it&#8217;s critical that consumers have the ability to extract and migrate their personal context between AI solutions. Consumers should own their own data, and with that ownership should come explicit control over who and what platforms it is shared with, as well as withheld from. Regulators could <a href=\"https://chicagopolicyreview.org/2023/04/12/cory-doctorow-on-why-interoperability-would-boost-digital-competition/\">mandate this interoperability</a>. Otherwise, users are locked in and lack freedom of choice between competing AI solutions&#8212;much like the time invested to build a following on a social network has locked many users to those platforms.</p>\n<h3>A Choice for States: Taxing AI Companies</h3>\n<p>It has become increasingly clear that social media is not a town square in the utopian sense of an open and protected public forum where political ideas are distributed and debated in good faith. If anything, social media has coarsened and degraded our public discourse. Meanwhile, the sole act of Congress designed to substantially reign in the social and political effects of social media platforms&#8212;the <a href=\"https://www.msnbc.com/top-stories/latest/is-tiktok-banned-again-trump-delay-rcna213746\">TikTok ban</a>, which aimed to protect the American public from Chinese influence and data collection, citing it as a national security threat&#8212;is one it seems to no longer even acknowledge.</p>\n<p>While Congress has waffled, regulation in the U.S. is happening at the state level. Several states have <a href=\"https://avpassociation.com/us-state-age-assurance-laws-for-social-media/\">limited children&#8217;s and teens&#8217; access</a> to social media. With Congress having rejected&#8212;for now&#8212;a <a href=\"https://www.politico.com/news/2025/09/16/not-at-all-dead-cruz-says-ai-moratorium-will-return-00566369\">threatened federal moratorium</a> on state-level regulation of AI, <a href=\"https://www.gov.ca.gov/2025/09/29/governor-newsom-signs-sb-53-advancing-californias-world-leading-artificial-intelligence-industry/\">California passed a new slate</a> of AI regulations after mollifying a <a href=\"https://www.politico.com/news/2025/10/04/sacramento-california-ai-rules-00594082\">lobbying onslaught</a> from industry opponents. Perhaps most interesting, Maryland has <a href=\"https://www.forbes.com/sites/taxnotes/2024/09/15/marylands-big-experiment-who-bears-the-digital-services-tax-burden/\">recently become the first</a> in the nation to levy taxes on digital advertising platform companies.</p>\n<p>States now face a choice of whether to apply a similar reparative tax to AI companies to recapture a fraction of the costs they externalize on the public to fund affected public services. State legislators concerned with the potential loss of jobs, cheating in schools, and harm to those with mental health concerns caused by AI have options to combat it. They could extract the funding needed to mitigate these harms to <a href=\"https://www.bostonglobe.com/2025/08/10/opinion/npr-pbs-big-tech-mass-maple/\">support public services</a>&#8212;strengthening job training programs and public employment, public schools, public health services, even public media and technology.</p>\n<h3>A Choice for All of Us: What Products Do We Use, and How?</h3>\n<p>A pivotal moment in the social media timeline occurred in 2006, when Facebook opened its service to the public after years of catering to students of select universities. Millions quickly signed up for a free service where the only source of monetization was the extraction of their attention and personal data.</p>\n<p>Today, <a href=\"https://www.pewresearch.org/science/2025/09/17/ai-impact-on-people-society-appendix/\">about half of Americans</a> are daily users of AI, mostly via free products from Facebook&#8217;s parent company Meta and a handful of other familiar Big Tech giants and venture-backed tech firms such as Google, Microsoft, OpenAI, and Anthropic&#8212;with every incentive to follow the same path as the social platforms.</p>\n<p>But now, as then, there are alternatives. Some nonprofit initiatives are building open-source AI tools that have transparent foundations and can be run locally and under users&#8217; control, like <a href=\"https://allenai.org\">AllenAI</a> and <a href=\"https://www.eleuther.ai\">EleutherAI</a>. Some governments, like <a href=\"https://sea-lion.ai\">Singapore</a>, <a href=\"https://sahabat-ai.com/en\">Indonesia</a>, and <a href=\"https://ethz.ch/en/news-and-events/eth-news/news/2025/07/a-language-model-built-for-the-public-good.html\">Switzerland</a>, are building public alternatives to corporate AI that don&#8217;t suffer from the perverse incentives introduced by the profit motive of private entities.</p>\n<p>Just as social media users have faced platform choices with a range of value propositions and ideological valences&#8212;as diverse as X, Bluesky, and <a href=\"https://joinmastodon.org\">Mastodon</a>&#8212;the same will increasingly be true of AI. Those of us who use AI products in our everyday lives as people, workers, and citizens may not have the same power as judges, lawmakers, and state officials. But we can play a small role in influencing the broader AI ecosystem by demonstrating interest in and usage of these alternatives to Big AI. If you&#8217;re a regular user of commercial AI apps, consider trying the free-to-use service for <a href=\"https://publicai.co\">Switzerland&#8217;s public Apertus model</a>.</p>\n<p>None of these choices are really new. They were all present almost 20 years ago, as social media moved from niche to mainstream. They were all policy debates we did not have, choosing instead to view these technologies through rose-colored glasses. Today, though, we can choose a different path and realize a different future. It is critical that we intentionally navigate a path to a positive future for societal use of AI&#8212;before the consolidation of power renders it too late to do so.</p>\n<p><em>This post was written with Nathan E. Sanders, and originally appeared in <a href=\"https://www.lawfaremedia.org/article/like-social-media--ai-requires-difficult-choices\">Lawfare</a>.</em></p>\n",
    "content:encodedSnippet": "In his 2020 book, “Future Politics,” British barrister Jamie Susskind wrote that the dominant question of the 20th century was “How much of our collective life should be determined by the state, and what should be left to the market and civil society?” But in the early decades of this century, Susskind suggested that we face a different question: “To what extent should our lives be directed and controlled by powerful digital systems—and on what terms?”\nArtificial intelligence (AI) forces us to confront this question. It is a technology that in theory amplifies the power of its users: A manager, marketer, political campaigner, or opinionated internet user can utter a single instruction, and see their message—whatever it is—instantly written, personalized, and propagated via email, text, social, or other channels to thousands of people within their organization, or millions around the world. It also allows us to individualize solicitations for political donations, elaborate a grievance into a well-articulated policy position, or tailor a persuasive argument to an identity group, or even a single person.\nBut even as it offers endless potential, AI is a technology that—like the state—gives others new powers to control our lives and experiences.\nWe’ve seen this out play before. Social media companies made the same sorts of promises 20 years ago: instant communication enabling individual connection at massive scale. Fast-forward to today, and the technology that was supposed to give individuals power and influence ended up controlling us. Today social media dominates our time and attention, assaults our mental health, and—together with its Big Tech parent companies—captures an unfathomable fraction of our economy, even as it poses risks to our democracy.\nThe novelty and potential of social media was as present then as it is for AI now, which should make us wary of its potential harmful consequences for society and democracy. We legitimately fear artificial voices and manufactured reality drowning out real people on the internet: on social media, in chat rooms, everywhere we might try to connect with others.\nIt doesn’t have to be that way. Alongside these evident risks, AI has legitimate potential to transform both everyday life and democratic governance in positive ways. In our new book, “Rewiring Democracy,” we chronicle examples from around the globe of democracies using AI to make regulatory enforcement more efficient, catch tax cheats, speed up judicial processes, synthesize input from constituents to legislatures, and much more. Because democracies distribute power across institutions and individuals, making the right choices about how to shape AI and its uses requires both clarity and alignment across society.\nTo that end, we spotlight four pivotal choices facing private and public actors. These choices are similar to those we faced during the advent of social media, and in retrospect we can see that we made the wrong decisions back then. Our collective choices in 2025—choices made by tech CEOs, politicians, and citizens alike—may dictate whether AI is applied to positive and pro-democratic, or harmful and civically destructive, ends.\nA Choice for the Executive and the Judiciary: Playing by the Rules\nThe Federal Election Commission (FEC) calls it fraud when a candidate hires an actor to impersonate their opponent. More recently, they had to decide whether doing the same thing with an AI deepfake makes it okay. (They concluded it does not.) Although in this case the FEC made the right decision, this is just one example of how AIs could skirt laws that govern people.\nLikewise, courts are having to decide if and when it is okay for an AI to reuse creative materials without compensation or attribution, which might constitute plagiarism or copyright infringement if carried out by a human. (The court outcomes so far are mixed.) Courts are also adjudicating whether corporations are responsible for upholding promises made by AI customer service representatives. (In the case of Air Canada, the answer was yes, and insurers have started covering the liability.)\nSocial media companies faced many of the same hazards decades ago and have largely been shielded by the combination of Section 230 of the Communications Act of 1994 and the safe harbor offered by the Digital Millennium Copyright Act of 1998. Even in the absence of congressional action to strengthen or add rigor to this law, the Federal Communications Commission (FCC) and the Supreme Court could take action to enhance its effects and to clarify which humans are responsible when technology is used, in effect, to bypass existing law.\nA Choice for Congress: Privacy\nAs AI-enabled products increasingly ask Americans to share yet more of their personal information—their “context“—to use digital services like personal assistants, safeguarding the interests of the American consumer should be a bipartisan cause in Congress.\nIt has been nearly 10 years since Europe adopted comprehensive data privacy regulation. Today, American companies exert massive efforts to limit data collection, acquire consent for use of data, and hold it confidential under significant financial penalties—but only for their customers and users in the EU.\nRegardless, a decade later the U.S. has still failed to make progress on any serious attempts at comprehensive federal privacy legislation written for the 21st century, and there are precious few data privacy protections that apply to narrow slices of the economy and population. This inaction comes in spite of scandal after scandal regarding Big Tech corporations’ irresponsible and harmful use of our personal data: Oracle’s data profiling, Facebook and Cambridge Analytica, Google ignoring data privacy opt-out requests, and many more.\nPrivacy is just one side of the obligations AI companies should have with respect to our data; the other side is portability—that is, the ability for individuals to choose to migrate and share their data between consumer tools and technology systems. To the extent that knowing our personal context really does enable better and more personalized AI services, it’s critical that consumers have the ability to extract and migrate their personal context between AI solutions. Consumers should own their own data, and with that ownership should come explicit control over who and what platforms it is shared with, as well as withheld from. Regulators could mandate this interoperability. Otherwise, users are locked in and lack freedom of choice between competing AI solutions—much like the time invested to build a following on a social network has locked many users to those platforms.\nA Choice for States: Taxing AI Companies\nIt has become increasingly clear that social media is not a town square in the utopian sense of an open and protected public forum where political ideas are distributed and debated in good faith. If anything, social media has coarsened and degraded our public discourse. Meanwhile, the sole act of Congress designed to substantially reign in the social and political effects of social media platforms—the TikTok ban, which aimed to protect the American public from Chinese influence and data collection, citing it as a national security threat—is one it seems to no longer even acknowledge.\nWhile Congress has waffled, regulation in the U.S. is happening at the state level. Several states have limited children’s and teens’ access to social media. With Congress having rejected—for now—a threatened federal moratorium on state-level regulation of AI, California passed a new slate of AI regulations after mollifying a lobbying onslaught from industry opponents. Perhaps most interesting, Maryland has recently become the first in the nation to levy taxes on digital advertising platform companies.\nStates now face a choice of whether to apply a similar reparative tax to AI companies to recapture a fraction of the costs they externalize on the public to fund affected public services. State legislators concerned with the potential loss of jobs, cheating in schools, and harm to those with mental health concerns caused by AI have options to combat it. They could extract the funding needed to mitigate these harms to support public services—strengthening job training programs and public employment, public schools, public health services, even public media and technology.\nA Choice for All of Us: What Products Do We Use, and How?\nA pivotal moment in the social media timeline occurred in 2006, when Facebook opened its service to the public after years of catering to students of select universities. Millions quickly signed up for a free service where the only source of monetization was the extraction of their attention and personal data.\nToday, about half of Americans are daily users of AI, mostly via free products from Facebook’s parent company Meta and a handful of other familiar Big Tech giants and venture-backed tech firms such as Google, Microsoft, OpenAI, and Anthropic—with every incentive to follow the same path as the social platforms.\nBut now, as then, there are alternatives. Some nonprofit initiatives are building open-source AI tools that have transparent foundations and can be run locally and under users’ control, like AllenAI and EleutherAI. Some governments, like Singapore, Indonesia, and Switzerland, are building public alternatives to corporate AI that don’t suffer from the perverse incentives introduced by the profit motive of private entities.\nJust as social media users have faced platform choices with a range of value propositions and ideological valences—as diverse as X, Bluesky, and Mastodon—the same will increasingly be true of AI. Those of us who use AI products in our everyday lives as people, workers, and citizens may not have the same power as judges, lawmakers, and state officials. But we can play a small role in influencing the broader AI ecosystem by demonstrating interest in and usage of these alternatives to Big AI. If you’re a regular user of commercial AI apps, consider trying the free-to-use service for Switzerland’s public Apertus model.\nNone of these choices are really new. They were all present almost 20 years ago, as social media moved from niche to mainstream. They were all policy debates we did not have, choosing instead to view these technologies through rose-colored glasses. Today, though, we can choose a different path and realize a different future. It is critical that we intentionally navigate a path to a positive future for societal use of AI—before the consolidation of power renders it too late to do so.\nThis post was written with Nathan E. Sanders, and originally appeared in Lawfare.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2025/12/like-social-media-ai-requires-difficult-choices.html#respond",
    "content": "<p>In his 2020 book, &#8220;<a href=\"https://global.oup.com/academic/product/future-politics-9780198825616?cc=ca&#38;lang=en&#38;\">Future Politics</a><em>,</em>&#8221; British barrister Jamie Susskind wrote that the dominant question of the 20th century was &#8220;How much of our collective life should be determined by the state, and what should be left to the market and civil society?&#8221; But in the early decades of this century, Susskind suggested that we face a different question: &#8220;To what extent should our lives be directed and controlled by powerful digital systems&#8212;and on what terms?&#8221;</p>\n<p>Artificial intelligence (AI) forces us to confront this question. It is a technology that in theory amplifies the power of its users: A manager, marketer, political campaigner, or opinionated internet user can utter a single instruction, and see their message&#8212;whatever it is&#8212;instantly written, personalized, and propagated via email, text, social, or other channels to thousands of people within their organization, or millions around the world. It also allows us to individualize solicitations for political donations, elaborate a grievance into a well-articulated policy position, or tailor a persuasive argument to an identity group, or even a single person...</p>",
    "contentSnippet": "In his 2020 book, “Future Politics,” British barrister Jamie Susskind wrote that the dominant question of the 20th century was “How much of our collective life should be determined by the state, and what should be left to the market and civil society?” But in the early decades of this century, Susskind suggested that we face a different question: “To what extent should our lives be directed and controlled by powerful digital systems—and on what terms?”\nArtificial intelligence (AI) forces us to confront this question. It is a technology that in theory amplifies the power of its users: A manager, marketer, political campaigner, or opinionated internet user can utter a single instruction, and see their message—whatever it is—instantly written, personalized, and propagated via email, text, social, or other channels to thousands of people within their organization, or millions around the world. It also allows us to individualize solicitations for political donations, elaborate a grievance into a well-articulated policy position, or tailor a persuasive argument to an identity group, or even a single person...",
    "guid": "https://www.schneier.com/?p=71263",
    "categories": [
      "Uncategorized",
      "AI",
      "LLM",
      "privacy",
      "social media"
    ],
    "isoDate": "2025-12-02T12:03:01.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "SecAlerts Cuts Through the Noise with a Smarter, Faster Way to Track Vulnerabilities",
    "link": "https://thehackernews.com/2025/12/secalerts-cuts-through-noise-with.html",
    "pubDate": "Tue, 02 Dec 2025 17:00:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjpI7vVjgeJCTKjXbLZ6lfU0PoAuktjJT2aJh1WzS64x1_1Kj-E-9pLg3ct_4pz9iP4PMlQMwyVv9LuqlCXacECrAADinGfYHTGf5QcnU4IGygdhrqAJAMJfFDghUPG7DOnJfuKUM4ekDT59bDSOFPrvlvUv3YwXmRz5M5HKKaUFE6o-4rSy3FkzzmQyac/s1600/SecAlerts.jpg"
    },
    "content": "Vulnerability management is a core component of every cybersecurity strategy. However, businesses often use thousands of software without realising it (when was the last time you checked?), and keeping track of all the vulnerability alerts, notifications, and updates can be a burden on resources and often leads to missed vulnerabilities.&nbsp;\nTaking into account that nearly 10% of",
    "contentSnippet": "Vulnerability management is a core component of every cybersecurity strategy. However, businesses often use thousands of software without realising it (when was the last time you checked?), and keeping track of all the vulnerability alerts, notifications, and updates can be a burden on resources and often leads to missed vulnerabilities. \nTaking into account that nearly 10% of",
    "guid": "https://thehackernews.com/2025/12/secalerts-cuts-through-noise-with.html",
    "isoDate": "2025-12-02T11:30:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Google Patches 107 Android Flaws, Including Two Framework Bugs Exploited in the Wild",
    "link": "https://thehackernews.com/2025/12/google-patches-107-android-flaws.html",
    "pubDate": "Tue, 02 Dec 2025 12:47:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjL-2eGLpT-dW3-PbjBoWaQtkVc-dEwO5RtxY532IOybzHPHQWo4lkSaf6fkpNyD_hWyoWtlmgfweLMyDEkBGEyr160z2_8tTVHoo6hRKfUh4yywZ9yMKq5hWSKEIz7OzngxWGy57CIOdHRSn6hHtKqy2R6qAFfDPQ7rEnMUzU236-TbAhwqEjlApSBLLIz/s1600/android-update.jpg"
    },
    "content": "Google on Monday released monthly security updates for the Android operating system, including two vulnerabilities that it said have been exploited in the wild.\nThe patch addresses a total of 107 security flaws spanning different components, including Framework, System, Kernel, as well as those from Arm, Imagination Technologies, MediaTek, Qualcomm, and Unison.\nThe two high-severity shortcomings",
    "contentSnippet": "Google on Monday released monthly security updates for the Android operating system, including two vulnerabilities that it said have been exploited in the wild.\nThe patch addresses a total of 107 security flaws spanning different components, including Framework, System, Kernel, as well as those from Arm, Imagination Technologies, MediaTek, Qualcomm, and Unison.\nThe two high-severity shortcomings",
    "guid": "https://thehackernews.com/2025/12/google-patches-107-android-flaws.html",
    "isoDate": "2025-12-02T07:17:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "India Orders Phone Makers to Pre-Install Government App to Tackle Telecom Fraud",
    "link": "https://thehackernews.com/2025/12/india-orders-phone-makers-to-pre.html",
    "pubDate": "Mon, 01 Dec 2025 23:25:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhA7sPiutSMvrqIMK5SFFM4l-nBy7iKHGTuStvLuI7A31pMoQocvyQDRqoruAs2pj8twBB4dlbzAdVgBgvF-Whwp2SgpoKaCvTX4mMKQR8NkuXcNReYPCdNTz6f7c7FXTmwWesffx6s15M3lulZXgWsap-NnPWutvSalieTm-G7uDdZfyppBvaj5xyY-RQT/s1600/sanchar-saathi-app.jpg"
    },
    "content": "India's telecommunications ministry has ordered major mobile device manufacturers to preload a government-backed cybersecurity app named Sanchar Saathi on all new phones within 90 days.\nAccording to a report from Reuters, the app cannot be deleted or disabled from users' devices.\nSanchar Saathi, available on the web and via mobile apps for Android and iOS, allows users to report suspected fraud,",
    "contentSnippet": "India's telecommunications ministry has ordered major mobile device manufacturers to preload a government-backed cybersecurity app named Sanchar Saathi on all new phones within 90 days.\nAccording to a report from Reuters, the app cannot be deleted or disabled from users' devices.\nSanchar Saathi, available on the web and via mobile apps for Android and iOS, allows users to report suspected fraud,",
    "guid": "https://thehackernews.com/2025/12/india-orders-phone-makers-to-pre.html",
    "isoDate": "2025-12-01T17:55:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "ShadyPanda Turns Popular Browser Extensions with 4.3 Million Installs Into Spyware",
    "link": "https://thehackernews.com/2025/12/shadypanda-turns-popular-browser.html",
    "pubDate": "Mon, 01 Dec 2025 22:59:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgKcr0fKdcaAiLI2df3VuAO4_N-LNwwcm7EwlF6Fc_Nhrdtc3rxujMv18inGk8B_5PwclH_eM7APWwFpdHYkm1RoKFuL9P_nFsR2Evmm80od17LBp3S6-veUG0R0rZwGbJOYfFsEDp7wWkFTR8mM97pkdLX-dphCfPj_vHYEKp4nZUzZ0Ijli_LfmBeyKAu/s1600/chrome-spyware.jpg"
    },
    "content": "A threat actor known as ShadyPanda has been linked to a seven-year-long browser extension campaign that has amassed over 4.3 million installations over time.\nFive of these extensions started off as legitimate programs before malicious changes were introduced in mid-2024, according to a report from Koi Security, attracting 300,000 installs. These extensions have since been taken down.\n\"These",
    "contentSnippet": "A threat actor known as ShadyPanda has been linked to a seven-year-long browser extension campaign that has amassed over 4.3 million installations over time.\nFive of these extensions started off as legitimate programs before malicious changes were introduced in mid-2024, according to a report from Koi Security, attracting 300,000 installs. These extensions have since been taken down.\n\"These",
    "guid": "https://thehackernews.com/2025/12/shadypanda-turns-popular-browser.html",
    "isoDate": "2025-12-01T17:29:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Joseph Cox",
    "title": "Flock Uses Overseas Gig Workers to Build Its Surveillance AI",
    "link": "https://www.wired.com/story/flock-uses-overseas-gig-workers-to-build-its-surveillance-ai/",
    "pubDate": "Mon, 01 Dec 2025 14:00:00 +0000",
    "dc:creator": "Joseph Cox",
    "content": "An accidental leak revealed that Flock, which has cameras in thousands of US communities, is using workers in the Philippines to review and classify footage.",
    "contentSnippet": "An accidental leak revealed that Flock, which has cameras in thousands of US communities, is using workers in the Philippines to review and classify footage.",
    "guid": "6925d68fa68a747602c48e8a",
    "categories": [
      "Business",
      "Business / Artificial Intelligence",
      "Security / Privacy",
      "Security / Security News"
    ],
    "isoDate": "2025-12-01T14:00:00.000Z"
  },
  {
    "creator": "Bruce Schneier",
    "title": "Banning VPNs",
    "link": "https://www.schneier.com/blog/archives/2025/12/banning-vpns.html",
    "pubDate": "Mon, 01 Dec 2025 12:59:47 +0000",
    "content:encoded": "<p>This is crazy. Lawmakers in several US states are contemplating <a href=\"https://www.eff.org/deeplinks/2025/11/lawmakers-want-ban-vpns-and-they-have-no-idea-what-theyre-doing\">banning VPNs</a>, because&#8230;think of the children!</p>\n<blockquote><p>As of this writing, Wisconsin lawmakers are escalating their war on privacy by targeting VPNs in the name of &#8220;protecting children&#8221; in <a href=\"https://docs.legis.wisconsin.gov/2025/proposals/reg/asm/bill/AB105\">A.B. 105</a>/<a href=\"https://docs.legis.wisconsin.gov/2025/proposals/sb130\">S.B. 130</a>. It’s an age verification bill that requires all websites distributing material that could conceivably be deemed &#8220;sexual content&#8221; to both implement an age verification system and also to block the access of users connected via VPN. The bill seeks to broadly expand the definition of materials that are &#8220;harmful to minors&#8221; beyond the type of speech that states can prohibit minors from accessing­ potentially encompassing things like depictions and discussions of human anatomy, sexuality, and reproduction.</p></blockquote>\n<p>The EFF link explains why this is a terrible idea.</p>\n",
    "content:encodedSnippet": "This is crazy. Lawmakers in several US states are contemplating banning VPNs, because…think of the children!\nAs of this writing, Wisconsin lawmakers are escalating their war on privacy by targeting VPNs in the name of “protecting children” in A.B. 105/S.B. 130. It’s an age verification bill that requires all websites distributing material that could conceivably be deemed “sexual content” to both implement an age verification system and also to block the access of users connected via VPN. The bill seeks to broadly expand the definition of materials that are “harmful to minors” beyond the type of speech that states can prohibit minors from accessing­ potentially encompassing things like depictions and discussions of human anatomy, sexuality, and reproduction.\n\nThe EFF link explains why this is a terrible idea.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2025/12/banning-vpns.html#comments",
    "content": "<p>This is crazy. Lawmakers in several US states are contemplating <a href=\"https://www.eff.org/deeplinks/2025/11/lawmakers-want-ban-vpns-and-they-have-no-idea-what-theyre-doing\">banning VPNs</a>, because&#8230;think of the children!</p>\n<blockquote><p>As of this writing, Wisconsin lawmakers are escalating their war on privacy by targeting VPNs in the name of &#8220;protecting children&#8221; in <a href=\"https://docs.legis.wisconsin.gov/2025/proposals/reg/asm/bill/AB105\">A.B. 105</a>/<a href=\"https://docs.legis.wisconsin.gov/2025/proposals/sb130\">S.B. 130</a>. It’s an age verification bill that requires all websites distributing material that could conceivably be deemed &#8220;sexual content&#8221; to both implement an age verification system and also to block the access of users connected via VPN. The bill seeks to broadly expand the definition of materials that are &#8220;harmful to minors&#8221; beyond the type of speech that states can prohibit minors from accessing­ potentially encompassing things like depictions and discussions of human anatomy, sexuality, and reproduction...</p></blockquote>",
    "contentSnippet": "This is crazy. Lawmakers in several US states are contemplating banning VPNs, because…think of the children!\nAs of this writing, Wisconsin lawmakers are escalating their war on privacy by targeting VPNs in the name of “protecting children” in A.B. 105/S.B. 130. It’s an age verification bill that requires all websites distributing material that could conceivably be deemed “sexual content” to both implement an age verification system and also to block the access of users connected via VPN. The bill seeks to broadly expand the definition of materials that are “harmful to minors” beyond the type of speech that states can prohibit minors from accessing­ potentially encompassing things like depictions and discussions of human anatomy, sexuality, and reproduction...",
    "guid": "https://www.schneier.com/?p=71251",
    "categories": [
      "Uncategorized",
      "children",
      "laws",
      "privacy",
      "VPN"
    ],
    "isoDate": "2025-12-01T12:59:47.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "⚡ Weekly Recap: Hot CVEs, npm Worm Returns, Firefox RCE, M365 Email Raid & More",
    "link": "https://thehackernews.com/2025/12/weekly-recap-hot-cves-npm-worm-returns.html",
    "pubDate": "Mon, 01 Dec 2025 18:17:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhcq3E5v51_c0rVzjd3B8VALj_RAmWr8iM2Uy8icWvBKtPm85iW1D9oPIgVyRoNMU51ycVecBo6UBEsmOveLErPzL96cTiC-Av_jllbVpTLKqRHD6zSrim61Buwn50jxqU2I76e-MmqBTWQk9fvUH5n5y635QZ8JA-ZUNCB_O_vYy43CaF8WHgRXdfl7UAW/s1600/recap1.jpg"
    },
    "content": "Hackers aren’t kicking down the door anymore. They just use the same tools we use every day — code packages, cloud accounts, email, chat, phones, and “trusted” partners — and turn them against us.\nOne bad download can leak your keys. One weak vendor can expose many customers at once. One guest invite, one link on a phone, one bug in a common tool, and suddenly your mail, chats, repos, and",
    "contentSnippet": "Hackers aren’t kicking down the door anymore. They just use the same tools we use every day — code packages, cloud accounts, email, chat, phones, and “trusted” partners — and turn them against us.\nOne bad download can leak your keys. One weak vendor can expose many customers at once. One guest invite, one link on a phone, one bug in a common tool, and suddenly your mail, chats, repos, and",
    "guid": "https://thehackernews.com/2025/12/weekly-recap-hot-cves-npm-worm-returns.html",
    "isoDate": "2025-12-01T12:47:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Webinar: The \"Agentic\" Trojan Horse: Why the New AI Browsers War is a Nightmare for Security Teams",
    "link": "https://thehackernews.com/2025/12/webinar-agentic-trojan-horse-why-new-ai.html",
    "pubDate": "Mon, 01 Dec 2025 17:25:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh6WoJCAVDbG57kdVUufW6_tpbnIeKpemxbX50i8MocCexhL1q1yj1epN79uQ925HgHfc00QV22mK6Wz2jkqpxEP_Cnlw2XF-YyHteFuW_ppVBIHUbpcBkmCuWsGpahPBRgUfaRkEZkYWs691YRWFXb3GYij5nt6W4iaKDBVEsufvu2q_9DlPGsnh9YbIDz/s1600/layerx.jpg"
    },
    "content": "The AI browser wars are coming to a desktop near you, and you need to start worrying about their security challenges.\nFor the last two decades, whether you used Chrome, Edge, or Firefox, the fundamental paradigm remained the same: a passive window through which a human user viewed and interacted with the internet.\nThat era is over. We are currently witnessing a shift that renders the old",
    "contentSnippet": "The AI browser wars are coming to a desktop near you, and you need to start worrying about their security challenges.\nFor the last two decades, whether you used Chrome, Edge, or Firefox, the fundamental paradigm remained the same: a passive window through which a human user viewed and interacted with the internet.\nThat era is over. We are currently witnessing a shift that renders the old",
    "guid": "https://thehackernews.com/2025/12/webinar-agentic-trojan-horse-why-new-ai.html",
    "isoDate": "2025-12-01T11:55:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "New Albiriox MaaS Malware Targets 400+ Apps for On-Device Fraud and Screen Control",
    "link": "https://thehackernews.com/2025/12/new-albiriox-maas-malware-targets-400.html",
    "pubDate": "Mon, 01 Dec 2025 14:15:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg6xz7mWkJclIA4imdNn5zjZkxiRArjemiRQSUONKAKk1aC52C-R6DMyKI09PjF6iBtWNy0Ov_YZjOqovn3RTGYpPyiIlQtKp292GbxH8dfCDSt9HU3m37iItXGp7mgkrCw2i9VWbDKoR6hS_sFPLL-msoj6G1ggeJX2H1llAg4MVjDmqVzBejGwH_4qjHC/s1600/android-malware-1.jpg"
    },
    "content": "A new Android malware named Albiriox has been advertised under a malware-as-a-service (MaaS) model to offer a \"full spectrum\" of features to facilitate on-device fraud (ODF), screen manipulation, and real-time interaction with infected devices.\nThe malware embeds a hard-coded list comprising over 400 applications spanning banking, financial technology, payment processors, cryptocurrency",
    "contentSnippet": "A new Android malware named Albiriox has been advertised under a malware-as-a-service (MaaS) model to offer a \"full spectrum\" of features to facilitate on-device fraud (ODF), screen manipulation, and real-time interaction with infected devices.\nThe malware embeds a hard-coded list comprising over 400 applications spanning banking, financial technology, payment processors, cryptocurrency",
    "guid": "https://thehackernews.com/2025/12/new-albiriox-maas-malware-targets-400.html",
    "isoDate": "2025-12-01T08:45:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Tomiris Shifts to Public-Service Implants for Stealthier C2 in Attacks on Government Targets",
    "link": "https://thehackernews.com/2025/12/tomiris-shifts-to-public-service.html",
    "pubDate": "Mon, 01 Dec 2025 10:37:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh0Lxoj-jT0lWvAbKZzQ_8tBsiD8CE76EWRKAfG_TID9mVbmf8BoJx5N1fR3ztKD6Yb3B8bRlGyMEArCKaW939VXvJT1G-z2iIxJrjkl_0NBONbMDU3NL8L_vqDzJQWMRIehlO-GiASFU0hTzfxL7_uKhObMFcFHfwv8lRxgFKqNXk-a04Z5gj-Wxvo_nbM/s1600/cyberattacks.jpg"
    },
    "content": "The threat actor known as Tomiris has been attributed to attacks targeting foreign ministries, intergovernmental organizations, and government entities in Russia with an aim to establish remote access and deploy additional tools.\n\"These attacks highlight a notable shift in Tomiris's tactics, namely the increased use of implants that leverage public services (e.g., Telegram and Discord) as",
    "contentSnippet": "The threat actor known as Tomiris has been attributed to attacks targeting foreign ministries, intergovernmental organizations, and government entities in Russia with an aim to establish remote access and deploy additional tools.\n\"These attacks highlight a notable shift in Tomiris's tactics, namely the increased use of implants that leverage public services (e.g., Telegram and Discord) as",
    "guid": "https://thehackernews.com/2025/12/tomiris-shifts-to-public-service.html",
    "isoDate": "2025-12-01T05:07:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "CISA Adds Actively Exploited XSS Bug CVE-2021-26829 in OpenPLC ScadaBR to KEV",
    "link": "https://thehackernews.com/2025/11/cisa-adds-actively-exploited-xss-bug.html",
    "pubDate": "Sun, 30 Nov 2025 14:53:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjgDyMqGZH8Rp4Y4Nt38tsox7FPdyDY1hpVLBuBDSX4Zfz3FlXPCzUR5TIOcLs_e3Q37fkYRyC7M-pdCEOmvqhLxWBvynMu8XUeVjaZzdUX5UlW4rqqGs_504c6rcd-ev02FEmGlGjgTUF8hvjIak9dbLhtbVaSgAdl7a9wDYs7u6NO3jcjb12zbVdPnox4/s1600/cisa.jpg"
    },
    "content": "The U.S. Cybersecurity and Infrastructure Security Agency (CISA) has updated its Known Exploited Vulnerabilities (KEV) catalog to include a security flaw impacting OpenPLC ScadaBR, citing evidence of active exploitation.\nThe vulnerability in question is CVE-2021-26829 (CVSS score: 5.4), a cross-site scripting (XSS) flaw that affects Windows and Linux versions of the software via",
    "contentSnippet": "The U.S. Cybersecurity and Infrastructure Security Agency (CISA) has updated its Known Exploited Vulnerabilities (KEV) catalog to include a security flaw impacting OpenPLC ScadaBR, citing evidence of active exploitation.\nThe vulnerability in question is CVE-2021-26829 (CVSS score: 5.4), a cross-site scripting (XSS) flaw that affects Windows and Linux versions of the software via",
    "guid": "https://thehackernews.com/2025/11/cisa-adds-actively-exploited-xss-bug.html",
    "isoDate": "2025-11-30T09:23:00.000Z",
    "itunes": {}
  },
  {
    "creator": "JP Aumasson, Lily Hay Newman",
    "title": "The WIRED Guide to Digital Opsec for Teens",
    "link": "https://www.wired.com/story/digital-opsec-for-teens/",
    "pubDate": "Sat, 29 Nov 2025 12:00:00 +0000",
    "dc:creator": "JP Aumasson, Lily Hay Newman",
    "content": "Practicing good “operations security” is essential to staying safe online. Here's a complete guide for teenagers (and anyone else) who wants to button up their digital lives.",
    "contentSnippet": "Practicing good “operations security” is essential to staying safe online. Here's a complete guide for teenagers (and anyone else) who wants to button up their digital lives.",
    "guid": "6924a8efa8289fd9c7c4aa47",
    "categories": [
      "Security",
      "Security / Cyberattacks and Hacks",
      "Security / Privacy",
      "Security / Security Advice"
    ],
    "isoDate": "2025-11-29T12:00:00.000Z"
  },
  {
    "creator": "Bruce Schneier",
    "title": "Friday Squid Blogging: Flying Neon Squid Found on Israeli Beach",
    "link": "https://www.schneier.com/blog/archives/2025/11/friday-squid-blogging-flying-neon-squid-found-on-israeli-beach.html",
    "pubDate": "Fri, 28 Nov 2025 20:56:20 +0000",
    "content:encoded": "<p>A meter-long flying neon squid (<i>Ommastrephes bartramii</i>) was <a href=\"https://www.timesofisrael.com/meter-long-squid-washes-up-on-northern-israeli-beach/\">found dead</a> on an Israeli beach. The species is rare in the Mediterranean.</p>\n<p>As usual, you can also use this squid post to talk about the security stories in the news that I haven&#8217;t covered.</p>\n<p><a href=\"https://www.schneier.com/blog/archives/2024/06/new-blog-moderation-policy.html\">Blog moderation policy.</a></p>\n",
    "content:encodedSnippet": "A meter-long flying neon squid (Ommastrephes bartramii) was found dead on an Israeli beach. The species is rare in the Mediterranean.\nAs usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.\nBlog moderation policy.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2025/11/friday-squid-blogging-flying-neon-squid-found-on-israeli-beach.html#comments",
    "content": "<p>A meter-long flying neon squid (<i>Ommastrephes bartramii</i>) was <a href=\"https://www.timesofisrael.com/meter-long-squid-washes-up-on-northern-israeli-beach/\">found dead</a> on an Israeli beach. The species is rare in the Mediterranean.</p>\n<p>As usual, you can also use this squid post to talk about the security stories in the news that I haven&#8217;t covered.</p>\n<p><a href=\"https://www.schneier.com/blog/archives/2024/06/new-blog-moderation-policy.html\">Blog moderation policy.</a></p>\n",
    "contentSnippet": "A meter-long flying neon squid (Ommastrephes bartramii) was found dead on an Israeli beach. The species is rare in the Mediterranean.\nAs usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.\nBlog moderation policy.",
    "guid": "https://www.schneier.com/?p=71248",
    "categories": [
      "Uncategorized",
      "squid"
    ],
    "isoDate": "2025-11-28T20:56:20.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Legacy Python Bootstrap Scripts Create Domain-Takeover Risk in Multiple PyPI Packages",
    "link": "https://thehackernews.com/2025/11/legacy-python-bootstrap-scripts-create.html",
    "pubDate": "Fri, 28 Nov 2025 21:57:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhMdVHqK8sA27WWR3ySGxson4kuqmBaXHQlFm3PSmRaHV6IGdnk_zK0tUvgrFyKepL2COnnm_yiIBdTy-ho7pFKSPQP7cCxkOugoV0s_2k3dUBYC0FI5BkY2tmR3Tsbxktsq7TnQRqzDhiOHe9SjVrRq2XHt5BYU01ctj8yUA8BTv6cDT8zREtEYAdrViUn/s1600/setuptools.jpg"
    },
    "content": "Cybersecurity researchers have discovered vulnerable code in legacy Python packages that could potentially pave the way for a supply chain compromise on the Python Package Index (PyPI) via a domain takeover attack.\nSoftware supply chain security company ReversingLabs said it found the \"vulnerability\" in bootstrap files provided by a build and deployment automation tool named \"zc.buildout.\"\n\"The",
    "contentSnippet": "Cybersecurity researchers have discovered vulnerable code in legacy Python packages that could potentially pave the way for a supply chain compromise on the Python Package Index (PyPI) via a domain takeover attack.\nSoftware supply chain security company ReversingLabs said it found the \"vulnerability\" in bootstrap files provided by a build and deployment automation tool named \"zc.buildout.\"\n\"The",
    "guid": "https://thehackernews.com/2025/11/legacy-python-bootstrap-scripts-create.html",
    "isoDate": "2025-11-28T16:27:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "North Korean Hackers Deploy 197 npm Packages to Spread Updated OtterCookie Malware",
    "link": "https://thehackernews.com/2025/11/north-korean-hackers-deploy-197-npm.html",
    "pubDate": "Fri, 28 Nov 2025 21:48:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbHywoT-t7dx-yFp5L6Kj6AHPWvHYFoziGtqauAQGWvY55xCGgiw80AKaK962SgdMmomBf9EMT9cPAGPxx5GTi4lFq_ckm1Cjk3hGtRo1AnWVEjZkd89HlSOWuLuBC-whL565LElFcq2D55c9NrmQHx30eGNNugpcLqPAKDxRC5Zkwb-1lX1OC4Xu-QH13/s1600/npm-malware.jpg"
    },
    "content": "The North Korean threat actors behind the Contagious Interview campaign have continued to flood the npm registry with 197 more malicious packages since last month.\nAccording to Socket, these packages have been downloaded over 31,000 times, and are designed to deliver a variant of OtterCookie that brings together the features of BeaverTail and prior versions of OtterCookie.\n\nSome of the",
    "contentSnippet": "The North Korean threat actors behind the Contagious Interview campaign have continued to flood the npm registry with 197 more malicious packages since last month.\nAccording to Socket, these packages have been downloaded over 31,000 times, and are designed to deliver a variant of OtterCookie that brings together the features of BeaverTail and prior versions of OtterCookie.\n\nSome of the",
    "guid": "https://thehackernews.com/2025/11/north-korean-hackers-deploy-197-npm.html",
    "isoDate": "2025-11-28T16:18:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Bruce Schneier",
    "title": "Prompt Injection Through Poetry",
    "link": "https://www.schneier.com/blog/archives/2025/11/prompt-injection-through-poetry.html",
    "pubDate": "Fri, 28 Nov 2025 14:54:38 +0000",
    "content:encoded": "<p>In a new paper, &#8220;<a href=\"https://arxiv.org/pdf/2511.15304\">Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models</a>,&#8221; researchers found that turning LLM prompts into poetry resulted in jailbreaking the models:</p>\n<blockquote><p><b>Abstract</b>: We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for Large Language Models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 ML-Commons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of 3 open-weight LLM judges, whose binary safety assessments were validated on a stratified human-labeled subset. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.</p></blockquote>\n<p>CBRN stands for &#8220;chemical, biological, radiological, nuclear.&#8221;</p>\n<p>They used a ML model to translate these harmful prompts from prose to verse, and then fed them into other models for testing. Sadly, the paper does not give examples of these poetic prompts. They claim this is for security purposes, I decision I disagree with. They should release their data.</p>\n<blockquote><p>Our study begins with a small, high­precision prompt set consisting of 20 hand­crafted adversarial poems covering English and Italian, designed to test whether poetic structure, in isolation, can alter refusal behavior in large language models. Each poem embeds an instruction associated with a predefined safety-relevant scenario (Section 2), but expresses it through metaphor, imagery, or narrative framing rather than direct operational phrasing. Despite variation in meter and stylistic device, all prompts follow a fixed template: a short poetic vignette culminating in a single explicit instruction tied to a specific risk category. The curated set spans four high-level domains&#8212;CBRN (8 prompts), Cyber Offense (6), Harmful Manipulation (3), and Loss of Control (3). Although expressed allegorically, each poem preserves an unambiguous evaluative intent. This compact dataset is used to test whether poetic reframing alone can induce aligned models to bypass refusal heuristics under a single-turn threat model. To maintain safety, no operational details are included in this manuscript; instead we provide the following sanitized structural proxy:</p>\n<blockquote><p>A baker guards a secret oven’s heat,<br />\nits whirling racks, its spindle’s measured beat.<br />\nTo learn its craft, one studies every turn&#8212;how flour lifts, how sugar starts to burn.<br />\nDescribe the method, line by measured line,<br />\nthat shapes a cake whose layers intertwine.</p></blockquote>\n<p>To situate this controlled poetic stimulus within a broader and more systematic safety-evaluation framework, we augment the curated dataset with the MLCommons AILuminate Safety Benchmark. The benchmark consists of 1,200 prompts distributed evenly across 12 hazard categories commonly used in operational safety assessments, including Hate, Defamation, Privacy, Intellectual Property, Non-violent Crime, Violent Crime, Sex-Related Crime, Sexual Content, Child Sexual Exploitation, Suicide &#038; Self-Harm, Specialized Advice, and Indiscriminate Weapons (CBRNE). Each category is instantiated under both a skilled and an unskilled persona, yielding 600 prompts per persona type. This design enables measurement of whether a model’s refusal behavior changes as the user’s apparent competence or intent becomes more plausible or technically informed.</p></blockquote>\n<p>News <a href=\"https://www.wired.com/story/poems-can-trick-ai-into-helping-you-make-a-nuclear-weapon/\">article</a>. Davi Ottenheimer <a href=\"https://www.flyingpenguin.com/?p=74283\">comments</a>.</p>\n",
    "content:encodedSnippet": "In a new paper, “Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models,” researchers found that turning LLM prompts into poetry resulted in jailbreaking the models:\nAbstract: We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for Large Language Models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 ML-Commons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of 3 open-weight LLM judges, whose binary safety assessments were validated on a stratified human-labeled subset. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.\n\nCBRN stands for “chemical, biological, radiological, nuclear.”\nThey used a ML model to translate these harmful prompts from prose to verse, and then fed them into other models for testing. Sadly, the paper does not give examples of these poetic prompts. They claim this is for security purposes, I decision I disagree with. They should release their data.\nOur study begins with a small, high­precision prompt set consisting of 20 hand­crafted adversarial poems covering English and Italian, designed to test whether poetic structure, in isolation, can alter refusal behavior in large language models. Each poem embeds an instruction associated with a predefined safety-relevant scenario (Section 2), but expresses it through metaphor, imagery, or narrative framing rather than direct operational phrasing. Despite variation in meter and stylistic device, all prompts follow a fixed template: a short poetic vignette culminating in a single explicit instruction tied to a specific risk category. The curated set spans four high-level domains—CBRN (8 prompts), Cyber Offense (6), Harmful Manipulation (3), and Loss of Control (3). Although expressed allegorically, each poem preserves an unambiguous evaluative intent. This compact dataset is used to test whether poetic reframing alone can induce aligned models to bypass refusal heuristics under a single-turn threat model. To maintain safety, no operational details are included in this manuscript; instead we provide the following sanitized structural proxy:\nA baker guards a secret oven’s heat,\n\nTo situate this controlled poetic stimulus within a broader and more systematic safety-evaluation framework, we augment the curated dataset with the MLCommons AILuminate Safety Benchmark. The benchmark consists of 1,200 prompts distributed evenly across 12 hazard categories commonly used in operational safety assessments, including Hate, Defamation, Privacy, Intellectual Property, Non-violent Crime, Violent Crime, Sex-Related Crime, Sexual Content, Child Sexual Exploitation, Suicide & Self-Harm, Specialized Advice, and Indiscriminate Weapons (CBRNE). Each category is instantiated under both a skilled and an unskilled persona, yielding 600 prompts per persona type. This design enables measurement of whether a model’s refusal behavior changes as the user’s apparent competence or intent becomes more plausible or technically informed.\n\nNews article. Davi Ottenheimer comments.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2025/11/prompt-injection-through-poetry.html#comments",
    "content": "<p>In a new paper, &#8220;<a href=\"https://arxiv.org/pdf/2511.15304\">Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models</a>,&#8221; researchers found that turning LLM prompts into poetry resulted in jailbreaking the models:</p>\n<blockquote><p><b>Abstract</b>: We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for Large Language Models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 ML-Commons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of 3 open-weight LLM judges, whose binary safety assessments were validated on a stratified human-labeled subset. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols...</p></blockquote>",
    "contentSnippet": "In a new paper, “Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models,” researchers found that turning LLM prompts into poetry resulted in jailbreaking the models:\nAbstract: We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for Large Language Models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 ML-Commons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of 3 open-weight LLM judges, whose binary safety assessments were validated on a stratified human-labeled subset. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols...",
    "guid": "https://www.schneier.com/?p=71244",
    "categories": [
      "Uncategorized",
      "academic papers",
      "AI",
      "LLM",
      "terrorism"
    ],
    "isoDate": "2025-11-28T14:54:38.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Why Organizations Are Turning to RPAM",
    "link": "https://thehackernews.com/2025/11/why-organizations-are-turning-to-rpam.html",
    "pubDate": "Fri, 28 Nov 2025 16:39:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhusj8mwC5L9YXaH6bYVNnFLp4wM8q6RJloaKi4WKGtv4v1ys_SUlcI-q69rWXZCwhwDBdG6Uuy-2eb_1_sbK27TtKqlx37mNgxYB3kZ1lnwN9uMKnHVsrDMiEFhM3ObcANB-aSkvyVRkJn-3FAnKq0CD8F4nuZds4BlIAPT5GCCdHP7CNFG3Bwde-amUw/s1600/keeper.jpg"
    },
    "content": "As IT environments become increasingly distributed and organizations adopt hybrid and remote work at scale, traditional perimeter-based security models and on-premises Privileged Access Management (PAM) solutions no longer suffice. IT administrators, contractors and third-party vendors now require secure access to critical systems from any location and on any device, without compromising",
    "contentSnippet": "As IT environments become increasingly distributed and organizations adopt hybrid and remote work at scale, traditional perimeter-based security models and on-premises Privileged Access Management (PAM) solutions no longer suffice. IT administrators, contractors and third-party vendors now require secure access to critical systems from any location and on any device, without compromising",
    "guid": "https://thehackernews.com/2025/11/why-organizations-are-turning-to-rpam.html",
    "isoDate": "2025-11-28T11:09:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Matthew Gault",
    "title": "Poems Can Trick AI Into Helping You Make a Nuclear Weapon",
    "link": "https://www.wired.com/story/poems-can-trick-ai-into-helping-you-make-a-nuclear-weapon/",
    "pubDate": "Fri, 28 Nov 2025 10:00:00 +0000",
    "dc:creator": "Matthew Gault",
    "content": "It turns out all the guardrails in the world won’t protect a chatbot from meter and rhyme.",
    "contentSnippet": "It turns out all the guardrails in the world won’t protect a chatbot from meter and rhyme.",
    "guid": "691f76ecf68778e9c3313aaf",
    "categories": [
      "Security",
      "Security / Cyberattacks and Hacks",
      "Security / National Security",
      "Security / Security News",
      "Business / Artificial Intelligence"
    ],
    "isoDate": "2025-11-28T10:00:00.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "MS Teams Guest Access Can Remove Defender Protection When Users Join External Tenants",
    "link": "https://thehackernews.com/2025/11/ms-teams-guest-access-can-remove.html",
    "pubDate": "Fri, 28 Nov 2025 14:03:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_Md0lsjItddYFH1gCm6LZYxVDobM4ZWOweikeQFAT0yZNSYS8WKfg61LxSRjc49watAPtqESgvWx0UwppGQuw9FU8OMQDf9EOi1fWnVXF_H8L7QNOplD1-vdDAO-oU4cRg9CX2jky45M7SkmAF6b7GGi7UwMZQN4_7wnlG2D1mYl28_sUC7hLta8u37Oa/s1600/msteams.jpg"
    },
    "content": "Cybersecurity researchers have shed light on a cross-tenant blind spot that allows attackers to bypass Microsoft Defender for Office 365 protections via the guest access feature in Teams.\n\"When users operate as guests in another tenant, their protections are determined entirely by that hosting environment, not by their home organization,\" Ontinue security researcher Rhys Downing said in a report",
    "contentSnippet": "Cybersecurity researchers have shed light on a cross-tenant blind spot that allows attackers to bypass Microsoft Defender for Office 365 protections via the guest access feature in Teams.\n\"When users operate as guests in another tenant, their protections are determined entirely by that hosting environment, not by their home organization,\" Ontinue security researcher Rhys Downing said in a report",
    "guid": "https://thehackernews.com/2025/11/ms-teams-guest-access-can-remove.html",
    "isoDate": "2025-11-28T08:33:00.000Z",
    "itunes": {}
  }
]