[
  {
    "creator": "Bruce Schneier",
    "title": "Upcoming Speaking Engagements",
    "link": "https://www.schneier.com/blog/archives/2025/12/upcoming-speaking-engagements-51.html",
    "pubDate": "Sun, 14 Dec 2025 17:10:39 +0000",
    "content:encoded": "<p>This is a current list of where and when I am scheduled to speak:</p>\n<ul>\n<li>I’m speaking and signing books at the <a href=\"https://chipublib.bibliocommons.com/events/693b4543ea69de6e000fc092\">Chicago Public Library</a> in Chicago, Illinois, USA, at 6:00 PM CT on February 5, 2026. Details to come.</li>\n<li>I’m speaking at <a href=\"https://www.capricon.org/capricon44/\">Capricon 44</a> in Chicago, Illinois, USA. The convention runs February 5-8, 2026. My speaking time is TBD.</li>\n<li>I’m speaking at the <a href=\"https://mcsc.io/\">Munich Cybersecurity Conference</a> in Munich, Germany on February 12, 2026.</li>\n<li>I’m speaking at <a href=\"https://techlivecyber.wsj.com/?gaa_at=eafs&amp;gaa_n=AWEtsqf9GP4etUdWaqDIATpiE9ycqWMIVoGIzjikYLlJ64hb6H_v1QH9OYhMTxeU51U%3D&amp;gaa_ts=691df89d&amp;gaa_sig=BG9fpWuP-liL7Gi3SJgXHmS02M4ob6lp6nOh94qnwVXCWYNzJxdzOiW365xA8vKeiulrErE8mbXDvKTcqktBtQ%3D%3D\">Tech Live: Cybersecurity</a> in New York City, USA on March 11, 2026.</li>\n<li>I’m giving the Ross Anderson Lecture at the University of Cambridge’s Churchill College on March 19, 2026.</li>\n<li>I’m speaking at RSAC 2026 in San Francisco, California, USA on March 25, 2026.</li>\n</ul>\n<p>The list is maintained on <a href=\"https://www.schneier.com/events/\">this page</a>.</p>\n",
    "content:encodedSnippet": "This is a current list of where and when I am scheduled to speak:\nI’m speaking and signing books at the Chicago Public Library in Chicago, Illinois, USA, at 6:00 PM CT on February 5, 2026. Details to come.\nI’m speaking at Capricon 44 in Chicago, Illinois, USA. The convention runs February 5-8, 2026. My speaking time is TBD.\nI’m speaking at the Munich Cybersecurity Conference in Munich, Germany on February 12, 2026.\nI’m speaking at Tech Live: Cybersecurity in New York City, USA on March 11, 2026.\nI’m giving the Ross Anderson Lecture at the University of Cambridge’s Churchill College on March 19, 2026.\nI’m speaking at RSAC 2026 in San Francisco, California, USA on March 25, 2026.\nThe list is maintained on this page.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2025/12/upcoming-speaking-engagements-51.html#respond",
    "content": "<p>This is a current list of where and when I am scheduled to speak:</p>\n<ul>\n<li>I’m speaking and signing books at the <a href=\"https://chipublib.bibliocommons.com/events/693b4543ea69de6e000fc092\">Chicago Public Library</a> in Chicago, Illinois, USA, at 6:00 PM CT on February 5, 2026. Details to come.</li>\n<li>I’m speaking at <a href=\"https://www.capricon.org/capricon44/\">Capricon 44</a> in Chicago, Illinois, USA. The convention runs February 5-8, 2026. My speaking time is TBD.</li>\n<li>I’m speaking at the <a href=\"https://mcsc.io/\">Munich Cybersecurity Conference</a> in Munich, Germany on February 12, 2026.</li>\n<li>I’m speaking at <a href=\"https://techlivecyber.wsj.com/?gaa_at=eafs&#38;gaa_n=AWEtsqf9GP4etUdWaqDIATpiE9ycqWMIVoGIzjikYLlJ64hb6H_v1QH9OYhMTxeU51U%3D&#38;gaa_ts=691df89d&#38;gaa_sig=BG9fpWuP-liL7Gi3SJgXHmS02M4ob6lp6nOh94qnwVXCWYNzJxdzOiW365xA8vKeiulrErE8mbXDvKTcqktBtQ%3D%3D\">Tech Live: Cybersecurity</a> in New York City, USA on March 11, 2026.</li>\n<li>I’m giving the Ross Anderson Lecture at the University of Cambridge’s Churchill College on March 19, 2026...</li></ul>",
    "contentSnippet": "This is a current list of where and when I am scheduled to speak:\nI’m speaking and signing books at the Chicago Public Library in Chicago, Illinois, USA, at 6:00 PM CT on February 5, 2026. Details to come.\nI’m speaking at Capricon 44 in Chicago, Illinois, USA. The convention runs February 5-8, 2026. My speaking time is TBD.\nI’m speaking at the Munich Cybersecurity Conference in Munich, Germany on February 12, 2026.\nI’m speaking at Tech Live: Cybersecurity in New York City, USA on March 11, 2026.\nI’m giving the Ross Anderson Lecture at the University of Cambridge’s Churchill College on March 19, 2026...",
    "guid": "https://www.schneier.com/?p=71334",
    "categories": [
      "Uncategorized",
      "Schneier news"
    ],
    "isoDate": "2025-12-14T17:10:39.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "CISA Adds Actively Exploited Sierra Wireless Router Flaw Enabling RCE Attacks",
    "link": "https://thehackernews.com/2025/12/cisa-adds-actively-exploited-sierra.html",
    "pubDate": "Sat, 13 Dec 2025 18:03:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEge8ZMStOlyoSh88jViO8HEQmAAac6HNtoVoR-ufVglteBHxv-YilKP9B3sA-BJRw19H_Bflza7JA59RvM0gq34FzgFeagwBFQeuh5OfQqBbXzRbP5cXA4NRhO8ybwpIJDQEmL1rF7TIPG5xHPhFZBxKfbI4Lr5jhllzl0AbElbRUTUypn89gpVj-esiu7Q/s1600/routers.jpg"
    },
    "content": "The U.S. Cybersecurity and Infrastructure Security Agency (CISA) on Friday added a high-severity flaw impacting Sierra Wireless AirLink ALEOS routers to its Known Exploited Vulnerabilities (KEV) catalog, following reports of active exploitation in the wild.\nCVE-2018-4063 (CVSS score: 8.8/9.9) refers to an unrestricted file upload vulnerability that could be exploited to achieve remote code",
    "contentSnippet": "The U.S. Cybersecurity and Infrastructure Security Agency (CISA) on Friday added a high-severity flaw impacting Sierra Wireless AirLink ALEOS routers to its Known Exploited Vulnerabilities (KEV) catalog, following reports of active exploitation in the wild.\nCVE-2018-4063 (CVSS score: 8.8/9.9) refers to an unrestricted file upload vulnerability that could be exploited to achieve remote code",
    "guid": "https://thehackernews.com/2025/12/cisa-adds-actively-exploited-sierra.html",
    "isoDate": "2025-12-13T12:33:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Lily Hay Newman, Matt Burgess",
    "title": "AI Toys for Kids Talk About Sex, Drugs, and Chinese Propaganda",
    "link": "https://www.wired.com/story/security-news-this-week-ai-toys-for-kids-talk-about-sex-drugs-and-chinese-propaganda/",
    "pubDate": "Sat, 13 Dec 2025 11:30:00 +0000",
    "dc:creator": "Lily Hay Newman, Matt Burgess",
    "content": "Plus: Travelers to the US may have to hand over five years of social media history, South Korean CEOs are resigning due to cyberattacks, and more.",
    "contentSnippet": "Plus: Travelers to the US may have to hand over five years of social media history, South Korean CEOs are resigning due to cyberattacks, and more.",
    "guid": "693c2880540dad19016a9558",
    "categories": [
      "Security",
      "Security / Cyberattacks and Hacks",
      "Security / National Security",
      "Security / Privacy",
      "Security / Security News"
    ],
    "isoDate": "2025-12-13T11:30:00.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Apple Issues Security Updates After Two WebKit Flaws Found Exploited in the Wild",
    "link": "https://thehackernews.com/2025/12/apple-issues-security-updates-after-two.html",
    "pubDate": "Sat, 13 Dec 2025 11:02:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSwTglRfB0k1FqqL7L502b4j1rqLa9StbW7akfVevnbqc0QsQHryjXRBajtpcOdiOOSUX119hpFSCGkZFuqxXH85aKyUMN2DwE0fKVDojo7uhXkZfEmf80438Wyd6Br5gASDHw6mLQxMc_fDPNGlgA1Op-YDJz8gYx6jqJhB_a9bKY66wuph0plkZdakTm/s1600/apple-update.jpg"
    },
    "content": "Apple on Friday released security updates for iOS, iPadOS, macOS, tvOS, watchOS, visionOS, and its Safari web browser to address two security flaws that it said have been exploited in the wild, one of which is the same flaw that was patched by Google in Chrome earlier this week.\nThe vulnerabilities are listed below -\n\nCVE-2025-43529 (CVSS score: N/A) - A use-after-free vulnerability in WebKit",
    "contentSnippet": "Apple on Friday released security updates for iOS, iPadOS, macOS, tvOS, watchOS, visionOS, and its Safari web browser to address two security flaws that it said have been exploited in the wild, one of which is the same flaw that was patched by Google in Chrome earlier this week.\nThe vulnerabilities are listed below -\n\nCVE-2025-43529 (CVSS score: N/A) - A use-after-free vulnerability in WebKit",
    "guid": "https://thehackernews.com/2025/12/apple-issues-security-updates-after-two.html",
    "isoDate": "2025-12-13T05:32:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Bruce Schneier",
    "title": "Friday Squid Blogging: Giant Squid Eating a Diamondback Squid",
    "link": "https://www.schneier.com/blog/archives/2025/12/friday-squid-blogging-giant-squid-eating-a-diamondback-squid.html",
    "pubDate": "Fri, 12 Dec 2025 22:00:30 +0000",
    "content:encoded": "<p>I have no context for <a href=\"https://www.reddit.com/r/interestingasfuck/comments/1pg0ujj/new_rare_footage_of_a_live_giant_squid_caught/\">this video</a>&#8212;it&#8217;s from Reddit&#8212;but one of the commenters adds some context:</p>\n<blockquote><p>Hey everyone, squid biologist here! Wanted to add some stuff you might find interesting.</p>\n<p>With so many people carrying around cameras, we&#8217;re getting more videos of giant squid at the surface than in previous decades. We&#8217;re also starting to notice a pattern, that around this time of year (peaking in January) we see a bunch of giant squid around Japan. We don&#8217;t know why this is happening. Maybe they gather around there to mate or something? who knows! but since so many people have cameras, those one-off monster-story encounters are now caught on video, like this one (which, btw, rips. This squid looks so healthy, it&#8217;s awesome).</p>\n<p>When we see big (giant or colossal) healthy squid like this, it&#8217;s often because a fisher caught something else (either another squid or sometimes an antarctic toothfish). The squid is attracted to whatever was caught and they hop on the hook and go along for the ride when the target species is reeled in. There are a few colossal squid sightings similar to this from the southern ocean (but fewer people are down there, so fewer cameras, fewer videos). On the original instagram video, a bunch of people are like &#8220;Put it back! Release him!&#8221; etc, but he&#8217;s just enjoying dinner (obviously as the squid swims away at the end).</p></blockquote>\n<p>As usual, you can also use this squid post to talk about the security stories in the news that I haven&#8217;t covered.</p>\n<p><a href=\"https://www.schneier.com/blog/archives/2024/06/new-blog-moderation-policy.html\">Blog moderation policy.</a></p>\n",
    "content:encodedSnippet": "I have no context for this video—it’s from Reddit—but one of the commenters adds some context:\nHey everyone, squid biologist here! Wanted to add some stuff you might find interesting.\nWith so many people carrying around cameras, we’re getting more videos of giant squid at the surface than in previous decades. We’re also starting to notice a pattern, that around this time of year (peaking in January) we see a bunch of giant squid around Japan. We don’t know why this is happening. Maybe they gather around there to mate or something? who knows! but since so many people have cameras, those one-off monster-story encounters are now caught on video, like this one (which, btw, rips. This squid looks so healthy, it’s awesome).\nWhen we see big (giant or colossal) healthy squid like this, it’s often because a fisher caught something else (either another squid or sometimes an antarctic toothfish). The squid is attracted to whatever was caught and they hop on the hook and go along for the ride when the target species is reeled in. There are a few colossal squid sightings similar to this from the southern ocean (but fewer people are down there, so fewer cameras, fewer videos). On the original instagram video, a bunch of people are like “Put it back! Release him!” etc, but he’s just enjoying dinner (obviously as the squid swims away at the end).\n\nAs usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.\nBlog moderation policy.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2025/12/friday-squid-blogging-giant-squid-eating-a-diamondback-squid.html#comments",
    "content": "<p>I have no context for <a href=\"https://www.reddit.com/r/interestingasfuck/comments/1pg0ujj/new_rare_footage_of_a_live_giant_squid_caught/\">this video</a>&#8212;it&#8217;s from Reddit&#8212;but one of the commenters adds some context:</p>\n<blockquote><p>Hey everyone, squid biologist here! Wanted to add some stuff you might find interesting.</p>\n<p>With so many people carrying around cameras, we&#8217;re getting more videos of giant squid at the surface than in previous decades. We&#8217;re also starting to notice a pattern, that around this time of year (peaking in January) we see a bunch of giant squid around Japan. We don&#8217;t know why this is happening. Maybe they gather around there to mate or something? who knows! but since so many people have cameras, those one-off monster-story encounters are now caught on video, like this one (which, btw, rips. This squid looks so healthy, it&#8217;s awesome)...</p></blockquote>",
    "contentSnippet": "I have no context for this video—it’s from Reddit—but one of the commenters adds some context:\nHey everyone, squid biologist here! Wanted to add some stuff you might find interesting.\nWith so many people carrying around cameras, we’re getting more videos of giant squid at the surface than in previous decades. We’re also starting to notice a pattern, that around this time of year (peaking in January) we see a bunch of giant squid around Japan. We don’t know why this is happening. Maybe they gather around there to mate or something? who knows! but since so many people have cameras, those one-off monster-story encounters are now caught on video, like this one (which, btw, rips. This squid looks so healthy, it’s awesome)...",
    "guid": "https://www.schneier.com/?p=71311",
    "categories": [
      "Uncategorized",
      "squid",
      "video"
    ],
    "isoDate": "2025-12-12T22:00:30.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Fake OSINT and GPT Utility GitHub Repos Spread PyStoreRAT Malware Payloads",
    "link": "https://thehackernews.com/2025/12/fake-osint-and-gpt-utility-github-repos.html",
    "pubDate": "Sat, 13 Dec 2025 00:20:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiYgcFxpYG91gB_qImBj80xopP9yPiTuHXJwTeIXOS92Fsj6dtv4A2LK3aQxVQGKfA6sJ7T5WfeX5CEFBFrPNNH96PY7qjHCbyb7yDH5WrATaFflCN3YgQxQZJlOlKaQLK0nDtbzGwlS0FrwBVm7CwEvPkr_qSbBR1fvXX-xxIZn6XdUspYS7k2c1j87330/s1600/git.jpg"
    },
    "content": "Cybersecurity researchers are calling attention to a new campaign that's leveraging GitHub-hosted Python repositories to distribute a previously undocumented JavaScript-based Remote Access Trojan (RAT) dubbed PyStoreRAT.\n\"These repositories, often themed as development utilities or OSINT tools, contain only a few lines of code responsible for silently downloading a remote HTA file and executing",
    "contentSnippet": "Cybersecurity researchers are calling attention to a new campaign that's leveraging GitHub-hosted Python repositories to distribute a previously undocumented JavaScript-based Remote Access Trojan (RAT) dubbed PyStoreRAT.\n\"These repositories, often themed as development utilities or OSINT tools, contain only a few lines of code responsible for silently downloading a remote HTA file and executing",
    "guid": "https://thehackernews.com/2025/12/fake-osint-and-gpt-utility-github-repos.html",
    "isoDate": "2025-12-12T18:50:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "New Advanced Phishing Kits Use AI and MFA Bypass Tactics to Steal Credentials at Scale",
    "link": "https://thehackernews.com/2025/12/new-advanced-phishing-kits-use-ai-and.html",
    "pubDate": "Fri, 12 Dec 2025 19:34:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg4a8r1ltQRVAHGAuHpS5vuzkIAKVgEgZQt0hi_nLCDg6akixRXUC_2sswGCHs8tFV2oLmaZd-YAwL-Yu09qMZMC64PZ2EQNycGfpxLzqwqGXaf1mPfKRZtx4XWLOKPXc1uyH_zVni2tBfNkiOUQL0Cdy4qqTRGu99eo6jDQbNq6O1-lvaZ8ZmKI3r9EG0c/s1600/1000039728.jpg"
    },
    "content": "Cybersecurity researchers have documented four new phishing kits named BlackForce, GhostFrame, InboxPrime AI, and Spiderman that are capable of facilitating credential theft at scale.\nBlackForce, first detected in August 2025, is designed to steal credentials and perform Man-in-the-Browser (MitB) attacks to capture one-time passwords (OTPs) and bypass multi-factor authentication (MFA). The kit",
    "contentSnippet": "Cybersecurity researchers have documented four new phishing kits named BlackForce, GhostFrame, InboxPrime AI, and Spiderman that are capable of facilitating credential theft at scale.\nBlackForce, first detected in August 2025, is designed to steal credentials and perform Man-in-the-Browser (MitB) attacks to capture one-time passwords (OTPs) and bypass multi-factor authentication (MFA). The kit",
    "guid": "https://thehackernews.com/2025/12/new-advanced-phishing-kits-use-ai-and.html",
    "isoDate": "2025-12-12T14:04:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Bruce Schneier",
    "title": "Building Trustworthy AI Agents",
    "link": "https://www.schneier.com/blog/archives/2025/12/building-trustworthy-ai-agents.html",
    "pubDate": "Fri, 12 Dec 2025 12:00:47 +0000",
    "content:encoded": "<p>The promise of personal AI assistants rests on a dangerous assumption: that we can trust systems we haven’t made trustworthy. We can’t. And today’s versions are failing us in predictable ways: pushing us to do things against our own best interests, gaslighting us with doubt about things we are or that we know, and being unable to distinguish between who we are and who we have been. They struggle with incomplete, inaccurate, and partial context: with no standard way to move toward accuracy, no mechanism to correct sources of error, and no accountability when wrong information leads to bad decisions.</p>\n<p>These aren’t edge cases. They’re the result of building AI systems without basic integrity controls. We’re in the third leg of data security&#8212;the old CIA triad. We’re good at availability and working on confidentiality, but we’ve never properly solved integrity. Now AI personalization has exposed the gap by accelerating the harms.</p>\n<p>The scope of the problem is large. A good AI assistant will need to be trained on everything we do and will need access to our most intimate personal interactions. This means an intimacy greater than your relationship with your email provider, your social media account, your cloud storage, or your phone. It requires an AI system that is both discreet and trustworthy when provided with that data. The system needs to be accurate and complete, but it also needs to be able to keep data private: to selectively disclose pieces of it when required, and to keep it secret otherwise. No current AI system is even close to meeting this.</p>\n<p>To further development along these lines, I and others have proposed separating users’ personal data stores from the AI systems that will use them. It makes sense; the engineering expertise that designs and develops AI systems is completely orthogonal to the security expertise that ensures the confidentiality and integrity of data. And by separating them, advances in security can proceed independently from advances in AI.</p>\n<p>What would this sort of personal data store look like? Confidentiality without integrity gives you access to wrong data. Availability without integrity gives you reliable access to corrupted data. Integrity enables the other two to be meaningful. Here are six requirements. They emerge from treating integrity as the organizing principle of security to make AI trustworthy.</p>\n<p>First, it would be broadly accessible as a data repository. We each want this data to include personal data about ourselves, as well as transaction data from our interactions. It would include data we create when interacting with others&#8212;emails, texts, social media posts&#8212;and revealed preference data as inferred by other systems. Some of it would be raw data, and some of it would be processed data: revealed preferences, conclusions inferred by other systems, maybe even raw weights in a personal LLM.</p>\n<p>Second, it would be broadly accessible as a source of data. This data would need to be made accessible to different LLM systems. This can’t be tied to a single AI model. Our AI future will include many different models&#8212;some of them chosen by us for particular tasks, and some thrust upon us by others. We would want the ability for any of those models to use our data.</p>\n<p>Third, it would need to be able to prove the accuracy of data. Imagine one of these systems being used to negotiate a bank loan, or participate in a first-round job interview with an AI recruiter. In these instances, the other party will want both relevant data and some sort of proof that the data are complete and accurate.</p>\n<p>Fourth, it would be under the user’s fine-grained control and audit. This is a deeply detailed personal dossier, and the user would need to have the final say in who could access it, what portions they could access, and under what circumstances. Users would need to be able to grant and revoke this access quickly and easily, and be able to go back in time and see who has accessed it.</p>\n<p>Fifth, it would be secure. The attacks against this system are numerous. There are the obvious read attacks, where an adversary attempts to learn a person’s data. And there are also write attacks, where adversaries add to or change a user’s data. Defending against both is critical; this all implies a complex and robust authentication system.</p>\n<p>Sixth, and finally, it must be easy to use. If we’re envisioning digital personal assistants for everybody, it can’t require specialized security training to use properly.</p>\n<p>I’m not the first to suggest something like this. Researchers have proposed a “Human Context Protocol” (https://papers.ssrn.com/sol3/ papers.cfm?abstract_id=5403981) that would serve as a neutral interface for personal data of this type. And in my capacity at a company called Inrupt, Inc., I have been working on an extension of Tim Berners-Lee’s Solid protocol for distributed data ownership.</p>\n<p>The engineering expertise to build AI systems is orthogonal to the security expertise needed to protect personal data. AI companies optimize for model performance, but data security requires cryptographic verification, access control, and auditable systems. Separating the two makes sense; you can’t ignore one or the other.</p>\n<p>Fortunately, decoupling personal data stores from AI systems means security can advance independently from performance (https:// ieeexplore.ieee.org/document/ 10352412). When you own and control your data store with high integrity, AI can’t easily manipulate you because you see what data it’s using and can correct it. It can’t easily gaslight you because you control the authoritative record of your context. And you determine which historical data are relevant or obsolete. Making this all work is a challenge, but it’s the only way we can have trustworthy AI assistants.</p>\n<p>This essay was originally published in <em>IEEE Security &amp; Privacy</em>.</p>\n",
    "content:encodedSnippet": "The promise of personal AI assistants rests on a dangerous assumption: that we can trust systems we haven’t made trustworthy. We can’t. And today’s versions are failing us in predictable ways: pushing us to do things against our own best interests, gaslighting us with doubt about things we are or that we know, and being unable to distinguish between who we are and who we have been. They struggle with incomplete, inaccurate, and partial context: with no standard way to move toward accuracy, no mechanism to correct sources of error, and no accountability when wrong information leads to bad decisions.\nThese aren’t edge cases. They’re the result of building AI systems without basic integrity controls. We’re in the third leg of data security—the old CIA triad. We’re good at availability and working on confidentiality, but we’ve never properly solved integrity. Now AI personalization has exposed the gap by accelerating the harms.\nThe scope of the problem is large. A good AI assistant will need to be trained on everything we do and will need access to our most intimate personal interactions. This means an intimacy greater than your relationship with your email provider, your social media account, your cloud storage, or your phone. It requires an AI system that is both discreet and trustworthy when provided with that data. The system needs to be accurate and complete, but it also needs to be able to keep data private: to selectively disclose pieces of it when required, and to keep it secret otherwise. No current AI system is even close to meeting this.\nTo further development along these lines, I and others have proposed separating users’ personal data stores from the AI systems that will use them. It makes sense; the engineering expertise that designs and develops AI systems is completely orthogonal to the security expertise that ensures the confidentiality and integrity of data. And by separating them, advances in security can proceed independently from advances in AI.\nWhat would this sort of personal data store look like? Confidentiality without integrity gives you access to wrong data. Availability without integrity gives you reliable access to corrupted data. Integrity enables the other two to be meaningful. Here are six requirements. They emerge from treating integrity as the organizing principle of security to make AI trustworthy.\nFirst, it would be broadly accessible as a data repository. We each want this data to include personal data about ourselves, as well as transaction data from our interactions. It would include data we create when interacting with others—emails, texts, social media posts—and revealed preference data as inferred by other systems. Some of it would be raw data, and some of it would be processed data: revealed preferences, conclusions inferred by other systems, maybe even raw weights in a personal LLM.\nSecond, it would be broadly accessible as a source of data. This data would need to be made accessible to different LLM systems. This can’t be tied to a single AI model. Our AI future will include many different models—some of them chosen by us for particular tasks, and some thrust upon us by others. We would want the ability for any of those models to use our data.\nThird, it would need to be able to prove the accuracy of data. Imagine one of these systems being used to negotiate a bank loan, or participate in a first-round job interview with an AI recruiter. In these instances, the other party will want both relevant data and some sort of proof that the data are complete and accurate.\nFourth, it would be under the user’s fine-grained control and audit. This is a deeply detailed personal dossier, and the user would need to have the final say in who could access it, what portions they could access, and under what circumstances. Users would need to be able to grant and revoke this access quickly and easily, and be able to go back in time and see who has accessed it.\nFifth, it would be secure. The attacks against this system are numerous. There are the obvious read attacks, where an adversary attempts to learn a person’s data. And there are also write attacks, where adversaries add to or change a user’s data. Defending against both is critical; this all implies a complex and robust authentication system.\nSixth, and finally, it must be easy to use. If we’re envisioning digital personal assistants for everybody, it can’t require specialized security training to use properly.\nI’m not the first to suggest something like this. Researchers have proposed a “Human Context Protocol” (https://papers.ssrn.com/sol3/ papers.cfm?abstract_id=5403981) that would serve as a neutral interface for personal data of this type. And in my capacity at a company called Inrupt, Inc., I have been working on an extension of Tim Berners-Lee’s Solid protocol for distributed data ownership.\nThe engineering expertise to build AI systems is orthogonal to the security expertise needed to protect personal data. AI companies optimize for model performance, but data security requires cryptographic verification, access control, and auditable systems. Separating the two makes sense; you can’t ignore one or the other.\nFortunately, decoupling personal data stores from AI systems means security can advance independently from performance (https:// ieeexplore.ieee.org/document/ 10352412). When you own and control your data store with high integrity, AI can’t easily manipulate you because you see what data it’s using and can correct it. It can’t easily gaslight you because you control the authoritative record of your context. And you determine which historical data are relevant or obsolete. Making this all work is a challenge, but it’s the only way we can have trustworthy AI assistants.\nThis essay was originally published in IEEE Security & Privacy.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2025/12/building-trustworthy-ai-agents.html#comments",
    "content": "<p>The promise of personal AI assistants rests on a dangerous assumption: that we can trust systems we haven’t made trustworthy. We can’t. And today’s versions are failing us in predictable ways: pushing us to do things against our own best interests, gaslighting us with doubt about things we are or that we know, and being unable to distinguish between who we are and who we have been. They struggle with incomplete, inaccurate, and partial context: with no standard way to move toward accuracy, no mechanism to correct sources of error, and no accountability when wrong information leads to bad decisions...</p>",
    "contentSnippet": "The promise of personal AI assistants rests on a dangerous assumption: that we can trust systems we haven’t made trustworthy. We can’t. And today’s versions are failing us in predictable ways: pushing us to do things against our own best interests, gaslighting us with doubt about things we are or that we know, and being unable to distinguish between who we are and who we have been. They struggle with incomplete, inaccurate, and partial context: with no standard way to move toward accuracy, no mechanism to correct sources of error, and no accountability when wrong information leads to bad decisions...",
    "guid": "https://www.schneier.com/?p=71323",
    "categories": [
      "Uncategorized",
      "AI",
      "data privacy",
      "LLM",
      "privacy",
      "trust"
    ],
    "isoDate": "2025-12-12T12:00:47.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Securing GenAI in the Browser: Policy, Isolation, and Data Controls That Actually Work",
    "link": "https://thehackernews.com/2025/12/securing-genai-in-browser-policy.html",
    "pubDate": "Fri, 12 Dec 2025 15:48:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhDv3XARtOUivvjEnErljioTinVDnawx7b3HwjUiP4I_0_JvCPo8jro-fI8ZJHESGp8sG0SMYH4BgfZqMQMeGA95kuzhe3z3m6GgMCtBdqRtLJ1WRKUHTJv8XoRLh8H7UXi3wMH0O9BhfsBsLyRFdsv53qh-TYgOwFr3PzpdsKcZ4QryozVIoGGJhVKP_c/s1600/ai.jpg"
    },
    "content": "The browser has become the main interface to GenAI for most enterprises: from web-based LLMs and copilots, to GenAI‑powered extensions and agentic browsers like ChatGPT Atlas. Employees are leveraging the power of GenAI to draft emails, summarize documents, work on code, and analyze data, often by copying/pasting sensitive information directly into prompts or uploading files.&nbsp;\nTraditional",
    "contentSnippet": "The browser has become the main interface to GenAI for most enterprises: from web-based LLMs and copilots, to GenAI‑powered extensions and agentic browsers like ChatGPT Atlas. Employees are leveraging the power of GenAI to draft emails, summarize documents, work on code, and analyze data, often by copying/pasting sensitive information directly into prompts or uploading files. \nTraditional",
    "guid": "https://thehackernews.com/2025/12/securing-genai-in-browser-policy.html",
    "isoDate": "2025-12-12T10:18:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "New React RSC Vulnerabilities Enable DoS and Source Code Exposure",
    "link": "https://thehackernews.com/2025/12/new-react-rsc-vulnerabilities-enable.html",
    "pubDate": "Fri, 12 Dec 2025 14:25:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgQz6FV9qkD3ZQ34_-_te7LAvOtZNopi3bQRTQq3TCojcBmPoef7tp-tgxFhffuFYyC5kvbdfEJMIBjwMn-rPElYlnpKG9kj89lPIAde8h_lYZRKq6a4mfiH6VWDXwIqFwimchyQ8M7RUvLd2_cAUi2aqcDyXZI_uDJcjfl1SyScuC96LV9RPhcDan3FJpQ/s1600/react-flaws.jpg"
    },
    "content": "The React team has released fixes for two new types of flaws in React Server Components (RSC) that, if successfully exploited, could result in denial-of-service (DoS) or source code exposure.\nThe team said the issues were found by the security community while attempting to exploit the patches released for CVE-2025-55182 (CVSS score: 10.0), a critical bug in RSC that has since been weaponized in",
    "contentSnippet": "The React team has released fixes for two new types of flaws in React Server Components (RSC) that, if successfully exploited, could result in denial-of-service (DoS) or source code exposure.\nThe team said the issues were found by the security community while attempting to exploit the patches released for CVE-2025-55182 (CVSS score: 10.0), a critical bug in RSC that has since been weaponized in",
    "guid": "https://thehackernews.com/2025/12/new-react-rsc-vulnerabilities-enable.html",
    "isoDate": "2025-12-12T08:55:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "React2Shell Exploitation Escalates into Large-Scale Global Attacks, Forcing Emergency Mitigation",
    "link": "https://thehackernews.com/2025/12/react2shell-exploitation-escalates-into.html",
    "pubDate": "Fri, 12 Dec 2025 14:11:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhhnft_k0pTnAA0gVIW1pPi9QlZ_5qU92WBv8wfMA9644HkYIF5DMGYcdZjGyDmHPm9WA5IoE1uLal-fqzhvX96S5gLUNTS38ggHySqo50T-brLivYF2HW2dDKYqfDJlu8kPGOuN5zVpy9w8kuC51Zz6Nsq3gQCdZ19snMvA-tfDAsFGryH6Qa1C1HMwS8M/s1600/react2shell-hacking.jpg"
    },
    "content": "The U.S. Cybersecurity and Infrastructure Security Agency (CISA) has urged federal agencies to patch the recent React2Shell vulnerability by December 12, 2025, amid reports of widespread exploitation.\nThe critical vulnerability, tracked as CVE-2025-55182 (CVSS score: 10.0), affects the React Server Components (RSC) Flight protocol. The underlying cause of the issue is an unsafe deserialization",
    "contentSnippet": "The U.S. Cybersecurity and Infrastructure Security Agency (CISA) has urged federal agencies to patch the recent React2Shell vulnerability by December 12, 2025, amid reports of widespread exploitation.\nThe critical vulnerability, tracked as CVE-2025-55182 (CVSS score: 10.0), affects the React Server Components (RSC) Flight protocol. The underlying cause of the issue is an unsafe deserialization",
    "guid": "https://thehackernews.com/2025/12/react2shell-exploitation-escalates-into.html",
    "isoDate": "2025-12-12T08:41:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "CISA Flags Actively Exploited GeoServer XXE Flaw in Updated KEV Catalog",
    "link": "https://thehackernews.com/2025/12/cisa-flags-actively-exploited-geoserver.html",
    "pubDate": "Fri, 12 Dec 2025 10:31:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiBN5buANAAdi4AundLfRH7dgLMFWvHQosALn-UulNEQC0ZZxUmTJUHQyS3meXA8rVRya72n3Wl-DsJRMM6VluFoSZSdm4Ha5SijPW09wRzOE2rpQmfh0JW113iEosXFEiel84OVcf-KWHWf4IjtWwxRd0lqdzPfsvf5qrP9bKcG6TCVEEy12h24ncJChnL/s1600/geo-server.jpg"
    },
    "content": "The U.S. Cybersecurity and Infrastructure Security Agency (CISA) on Thursday added a high-severity security flaw impacting OSGeo GeoServer to its Known Exploited Vulnerabilities (KEV) catalog, based on evidence of active exploitation in the wild.\nThe vulnerability in question is CVE-2025-58360 (CVSS score: 8.2), an unauthenticated XML External Entity (XXE) flaw that affects all versions prior to",
    "contentSnippet": "The U.S. Cybersecurity and Infrastructure Security Agency (CISA) on Thursday added a high-severity security flaw impacting OSGeo GeoServer to its Known Exploited Vulnerabilities (KEV) catalog, based on evidence of active exploitation in the wild.\nThe vulnerability in question is CVE-2025-58360 (CVSS score: 8.2), an unauthenticated XML External Entity (XXE) flaw that affects all versions prior to",
    "guid": "https://thehackernews.com/2025/12/cisa-flags-actively-exploited-geoserver.html",
    "isoDate": "2025-12-12T05:01:00.000Z",
    "itunes": {}
  },
  {
    "creator": "Dell Cameron",
    "title": "Warnings Mount in Congress Over Expanded US Wiretap Powers",
    "link": "https://www.wired.com/story/warnings-mount-in-congress-over-expanded-us-wiretap-powers/",
    "pubDate": "Thu, 11 Dec 2025 22:15:56 +0000",
    "dc:creator": "Dell Cameron",
    "content": "Experts tell US lawmakers that a crucial spy program’s safeguards are failing, allowing intel agencies deeper, unconstrained access to Americans’ data.",
    "contentSnippet": "Experts tell US lawmakers that a crucial spy program’s safeguards are failing, allowing intel agencies deeper, unconstrained access to Americans’ data.",
    "guid": "693adec55885de020c5e2195",
    "categories": [
      "Security",
      "Security / National Security",
      "Security / Privacy",
      "Security / Security News",
      "Politics / Policy"
    ],
    "isoDate": "2025-12-11T22:15:56.000Z"
  },
  {
    "creator": "David Gilbert",
    "title": "Doxers Posing as Cops Are Tricking Big Tech Firms Into Sharing People’s Private Data",
    "link": "https://www.wired.com/story/doxers-posing-as-cops-are-tricking-big-tech-firms-into-sharing-peoples-private-data/",
    "pubDate": "Thu, 11 Dec 2025 18:54:50 +0000",
    "dc:creator": "David Gilbert",
    "content": "A spoofed email address and an easily faked document is all it takes for major tech companies to hand over your most personal information.",
    "contentSnippet": "A spoofed email address and an easily faked document is all it takes for major tech companies to hand over your most personal information.",
    "guid": "692ddce5259b04d366e07261",
    "categories": [
      "Security",
      "Security / Privacy",
      "Security / Security News"
    ],
    "isoDate": "2025-12-11T18:54:50.000Z"
  },
  {
    "creator": "Bruce Schneier",
    "title": "AIs Exploiting Smart Contracts",
    "link": "https://www.schneier.com/blog/archives/2025/12/ais-exploiting-smart-contracts.html",
    "pubDate": "Thu, 11 Dec 2025 17:06:05 +0000",
    "content:encoded": "<p>I have long maintained that smart contracts are a dumb idea: that a human process is actually a security feature.</p>\n<p>Here&#8217;s some <a href=\"https://red.anthropic.com/2025/smart-contracts/\">interesting research</a> on training AIs to automatically exploit smart contracts:</p>\n<blockquote><p>AI models are increasingly good at cyber tasks, as we&#8217;ve <a href=\"https://red.anthropic.com/2025/ai-for-cyber-defenders/\">written about before</a>. But what is the economic impact of these capabilities? In a recent <a href=\"https://www.matsprogram.org/\">MATS</a> and Anthropic Fellows project, our scholars investigated this question by evaluating AI agents&#8217; ability to exploit smart contracts on <a href=\"https://github.com/safety-research/SmartContract-bench\">Smart CONtracts Exploitation benchmark (SCONE-bench)</a>­a new benchmark they built comprising 405 contracts that were actually exploited between 2020 and 2025. On contracts exploited after the latest knowledge cutoffs (June 2025 for Opus 4.5 and March 2025 for other models), Claude Opus 4.5, Claude Sonnet 4.5, and GPT-5 developed exploits collectively worth $4.6 million, establishing a concrete lower bound for the economic harm these capabilities could enable. Going beyond retrospective analysis, we evaluated both Sonnet 4.5 and GPT-5 in simulation against 2,849 recently deployed contracts without any known vulnerabilities. Both agents uncovered two novel zero-day vulnerabilities and produced exploits worth $3,694, with GPT-5 doing so at an API cost of $3,476. This demonstrates as a proof-of-concept that profitable, real-world autonomous exploitation is technically feasible, a finding that underscores the need for proactive adoption of AI for defense.</p></blockquote>\n",
    "content:encodedSnippet": "I have long maintained that smart contracts are a dumb idea: that a human process is actually a security feature.\nHere’s some interesting research on training AIs to automatically exploit smart contracts:\nAI models are increasingly good at cyber tasks, as we’ve written about before. But what is the economic impact of these capabilities? In a recent MATS and Anthropic Fellows project, our scholars investigated this question by evaluating AI agents’ ability to exploit smart contracts on Smart CONtracts Exploitation benchmark (SCONE-bench)­a new benchmark they built comprising 405 contracts that were actually exploited between 2020 and 2025. On contracts exploited after the latest knowledge cutoffs (June 2025 for Opus 4.5 and March 2025 for other models), Claude Opus 4.5, Claude Sonnet 4.5, and GPT-5 developed exploits collectively worth $4.6 million, establishing a concrete lower bound for the economic harm these capabilities could enable. Going beyond retrospective analysis, we evaluated both Sonnet 4.5 and GPT-5 in simulation against 2,849 recently deployed contracts without any known vulnerabilities. Both agents uncovered two novel zero-day vulnerabilities and produced exploits worth $3,694, with GPT-5 doing so at an API cost of $3,476. This demonstrates as a proof-of-concept that profitable, real-world autonomous exploitation is technically feasible, a finding that underscores the need for proactive adoption of AI for defense.",
    "dc:creator": "Bruce Schneier",
    "comments": "https://www.schneier.com/blog/archives/2025/12/ais-exploiting-smart-contracts.html#comments",
    "content": "<p>I have long maintained that smart contracts are a dumb idea: that a human process is actually a security feature.</p>\n<p>Here&#8217;s some <a href=\"https://red.anthropic.com/2025/smart-contracts/\">interesting research</a> on training AIs to automatically exploit smart contracts:</p>\n<blockquote><p>AI models are increasingly good at cyber tasks, as we&#8217;ve <a href=\"https://red.anthropic.com/2025/ai-for-cyber-defenders/\">written about before</a>. But what is the economic impact of these capabilities? In a recent <a href=\"https://www.matsprogram.org/\">MATS</a> and Anthropic Fellows project, our scholars investigated this question by evaluating AI agents&#8217; ability to exploit smart contracts on <a href=\"https://github.com/safety-research/SmartContract-bench\">Smart CONtracts Exploitation benchmark (SCONE-bench)</a>­a new benchmark they built comprising 405 contracts that were actually exploited between 2020 and 2025. On contracts exploited after the latest knowledge cutoffs (June 2025 for Opus 4.5 and March 2025 for other models), Claude Opus 4.5, Claude Sonnet 4.5, and GPT-5 developed exploits collectively worth $4.6 million, establishing a concrete lower bound for the economic harm these capabilities could enable. Going beyond retrospective analysis, we evaluated both Sonnet 4.5 and GPT-5 in simulation against 2,849 recently deployed contracts without any known vulnerabilities. Both agents uncovered two novel zero-day vulnerabilities and produced exploits worth $3,694, with GPT-5 doing so at an API cost of $3,476. This demonstrates as a proof-of-concept that profitable, real-world autonomous exploitation is technically feasible, a finding that underscores the need for proactive adoption of AI for defense...</p></blockquote>",
    "contentSnippet": "I have long maintained that smart contracts are a dumb idea: that a human process is actually a security feature.\nHere’s some interesting research on training AIs to automatically exploit smart contracts:\nAI models are increasingly good at cyber tasks, as we’ve written about before. But what is the economic impact of these capabilities? In a recent MATS and Anthropic Fellows project, our scholars investigated this question by evaluating AI agents’ ability to exploit smart contracts on Smart CONtracts Exploitation benchmark (SCONE-bench)­a new benchmark they built comprising 405 contracts that were actually exploited between 2020 and 2025. On contracts exploited after the latest knowledge cutoffs (June 2025 for Opus 4.5 and March 2025 for other models), Claude Opus 4.5, Claude Sonnet 4.5, and GPT-5 developed exploits collectively worth $4.6 million, establishing a concrete lower bound for the economic harm these capabilities could enable. Going beyond retrospective analysis, we evaluated both Sonnet 4.5 and GPT-5 in simulation against 2,849 recently deployed contracts without any known vulnerabilities. Both agents uncovered two novel zero-day vulnerabilities and produced exploits worth $3,694, with GPT-5 doing so at an API cost of $3,476. This demonstrates as a proof-of-concept that profitable, real-world autonomous exploitation is technically feasible, a finding that underscores the need for proactive adoption of AI for defense...",
    "guid": "https://www.schneier.com/?p=71315",
    "categories": [
      "Uncategorized",
      "academic papers",
      "AI",
      "blockchain",
      "exploits"
    ],
    "isoDate": "2025-12-11T17:06:05.000Z"
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "ThreatsDay Bulletin: Spyware Alerts, Mirai Strikes, Docker Leaks, ValleyRAT Rootkit — and 20 More Stories",
    "link": "https://thehackernews.com/2025/12/threatsday-bulletin-spyware-alerts.html",
    "pubDate": "Thu, 11 Dec 2025 19:10:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgcBEIOMDHFHbMxpqG8wwxxLRZJ4TavL-Z4AoU09ldjKg_8LpfxabE_BKPBfWUHK8GClxPJ2r3BRs078HZ8KwPrMHVHS1m5ZcCdPNR9mtUD5SZfz6WE3FLp6KnoT6HY2UhC-uV7CxqoFYiPyJw_4V0r0A5-vgSI0Znq74OKWlQxr6morZEwQUBaZd89AVg9/s1600/threatsday.jpg"
    },
    "content": "This week’s cyber stories show how fast the online world can turn risky. Hackers are sneaking malware into movie downloads, browser add-ons, and even software updates people trust. Tech giants and governments are racing to plug new holes while arguing over privacy and control. And researchers keep uncovering just how much of our digital life is still wide open.\nThe new Threatsday Bulletin",
    "contentSnippet": "This week’s cyber stories show how fast the online world can turn risky. Hackers are sneaking malware into movie downloads, browser add-ons, and even software updates people trust. Tech giants and governments are racing to plug new holes while arguing over privacy and control. And researchers keep uncovering just how much of our digital life is still wide open.\nThe new Threatsday Bulletin",
    "guid": "https://thehackernews.com/2025/12/threatsday-bulletin-spyware-alerts.html",
    "isoDate": "2025-12-11T13:40:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "NANOREMOTE Malware Uses Google Drive API for Hidden Control on Windows Systems",
    "link": "https://thehackernews.com/2025/12/nanoremote-malware-uses-google-drive.html",
    "pubDate": "Thu, 11 Dec 2025 18:46:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsKOtWgjKbDTJ_bQIFriTn7SS-6j1OkejHAL8qQ8rAg03gXgLRrv0-qYN2W_QQI8BqUBcmOxNFqni0N9fU5QpzCQdVFPybji0uX397JN_RP1BeefHSJr5Z5LcAhT15toz_P7LJLhz2T7U_xsTG0yzGsUdA4NaJnLvk7gyPjPw8lEFgKu87aGj8cIt_1xyy/s1600/gdrive.jpg"
    },
    "content": "Cybersecurity researchers have disclosed details of a new fully-featured Windows backdoor called NANOREMOTE that uses the Google Drive API for command-and-control (C2) purposes.\nAccording to a report from Elastic Security Labs, the malware shares code similarities with another implant codenamed FINALDRAFT (aka Squidoor) that employs Microsoft Graph API for C2. FINALDRAFT is attributed to a",
    "contentSnippet": "Cybersecurity researchers have disclosed details of a new fully-featured Windows backdoor called NANOREMOTE that uses the Google Drive API for command-and-control (C2) purposes.\nAccording to a report from Elastic Security Labs, the malware shares code similarities with another implant codenamed FINALDRAFT (aka Squidoor) that employs Microsoft Graph API for C2. FINALDRAFT is attributed to a",
    "guid": "https://thehackernews.com/2025/12/nanoremote-malware-uses-google-drive.html",
    "isoDate": "2025-12-11T13:16:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "The Impact of Robotic Process Automation (RPA) on Identity and Access Management",
    "link": "https://thehackernews.com/2025/12/the-impact-of-robotic-process.html",
    "pubDate": "Thu, 11 Dec 2025 17:00:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhkHa_ZsEZyIsKJkBKWhgZBt2Oo3VGKY_5ZeOaoO74V_TbabWN-GlLYtOPjpjnqS63ufmXSWt2jnwRglhgFqzJTGGHqOO04K3wn6V3lN6IJdsNupy7M1V9yKe5895zGyjmnme7207WatecL_hIzgwWMYo5AvT3ecXh7PYHwDCAZw5NjY5iDiIFWkzO7pmw/s1600/keeper.jpg"
    },
    "content": "As enterprises refine their strategies for handling Non-Human Identities (NHIs), Robotic Process Automation (RPA) has become a powerful tool for streamlining operations and enhancing security. However, since RPA bots have varying levels of access to sensitive information, enterprises must be prepared to mitigate a variety of challenges. In large organizations, bots are starting to outnumber",
    "contentSnippet": "As enterprises refine their strategies for handling Non-Human Identities (NHIs), Robotic Process Automation (RPA) has become a powerful tool for streamlining operations and enhancing security. However, since RPA bots have varying levels of access to sensitive information, enterprises must be prepared to mitigate a variety of challenges. In large organizations, bots are starting to outnumber",
    "guid": "https://thehackernews.com/2025/12/the-impact-of-robotic-process.html",
    "isoDate": "2025-12-11T11:30:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "WIRTE Leverages AshenLoader Sideloading to Install the AshTag Espionage Backdoor",
    "link": "https://thehackernews.com/2025/12/wirte-leverages-ashenloader-sideloading.html",
    "pubDate": "Thu, 11 Dec 2025 16:30:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSr-PT3dj-KXpKptjdRmfwueMOhO5kNQWOHyylqmUj0nCT9BOb9UM7svBOwdWmnJipRU9vjO2l7WjVGJZc-U9jXCPpolj-GYZsBrP3x5AB4fInWxKVtZOYV6HNxCytEfbfgwWe21IE5k5VhcRMrouTw4DsYt9k2ZcjikVbPKI6UhoxutGP46v110aTra7i/s1600/backdoor.jpg"
    },
    "content": "An advanced persistent threat (APT) known as WIRTE has been attributed to attacks targeting government and diplomatic entities across the Middle East with a previously undocumented malware suite dubbed AshTag since 2020.\nPalo Alto Networks Unit 42 is tracking the activity cluster under the name Ashen Lepus. Artifacts uploaded to the VirusTotal platform show that the threat actor has trained its",
    "contentSnippet": "An advanced persistent threat (APT) known as WIRTE has been attributed to attacks targeting government and diplomatic entities across the Middle East with a previously undocumented malware suite dubbed AshTag since 2020.\nPalo Alto Networks Unit 42 is tracking the activity cluster under the name Ashen Lepus. Artifacts uploaded to the VirusTotal platform show that the threat actor has trained its",
    "guid": "https://thehackernews.com/2025/12/wirte-leverages-ashenloader-sideloading.html",
    "isoDate": "2025-12-11T11:00:00.000Z",
    "itunes": {}
  },
  {
    "creator": "info@thehackernews.com (The Hacker News)",
    "title": "Unpatched Gogs Zero-Day Exploited Across 700+ Instances Amid Active Attacks",
    "link": "https://thehackernews.com/2025/12/unpatched-gogs-zero-day-exploited.html",
    "pubDate": "Thu, 11 Dec 2025 16:00:00 +0530",
    "author": "info@thehackernews.com (The Hacker News)",
    "enclosure": {
      "length": "12216320",
      "type": "image/jpeg",
      "url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh6OJVsDspcCdye7M8PSggWU392C8E30egOw45ke_JjhGPAv-Au_u34ejTw7mT307EGecNF77LcAz2Kzw6Mhyphenhyphenhjl956WA2poNcT3kP3eIhMKjv3vqDJabkLtachFO7EPl-c8ROOH771RwuVd5KPhSBTSS10wG1qKhLRNxDLtLF59V4G1hvD2dn3LZrHCmBU/s1600/gg.jpg"
    },
    "content": "A high-severity unpatched security vulnerability in Gogs has come under active exploitation, with more than 700 compromised instances accessible over the internet, according to new findings from Wiz.\nThe flaw, tracked as CVE-2025-8110 (CVSS score: 8.7), is a case of file overwrite in the file update API of the Go-based self-hosted Git service. A fix for the issue is said to be currently in the",
    "contentSnippet": "A high-severity unpatched security vulnerability in Gogs has come under active exploitation, with more than 700 compromised instances accessible over the internet, according to new findings from Wiz.\nThe flaw, tracked as CVE-2025-8110 (CVSS score: 8.7), is a case of file overwrite in the file update API of the Go-based self-hosted Git service. A fix for the issue is said to be currently in the",
    "guid": "https://thehackernews.com/2025/12/unpatched-gogs-zero-day-exploited.html",
    "isoDate": "2025-12-11T10:30:00.000Z",
    "itunes": {}
  }
]